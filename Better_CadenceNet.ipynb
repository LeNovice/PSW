{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeNovice/PSW/blob/main/Better_CadenceNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BCeppY1fBRsz"
      },
      "outputs": [],
      "source": [
        "USE_ORIGINAL = 0\n",
        "loss = 'categorical_crossentropy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IYvbodAaO5NT"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "#For plotting the dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#Data pipeline preparation\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "#model building\n",
        "from tensorflow.keras import models\n",
        "import tensorflow.keras.utils as tfutils\n",
        "import os\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bJSJfW_tPA88"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 10\n",
        "\n",
        "DataSet = 'cifar10'\n",
        "#'caltech101'\n",
        "#'cifar10'\n",
        "def num_samples_per_class(ds_train, get_top_10 = False, print_all = False):\n",
        "    vals = np.unique(np.fromiter(ds_train.map(lambda x, y: y), int), return_counts=True)\n",
        "    class_list = []\n",
        "    class_hist = []\n",
        "    for val,count in zip(*vals):\n",
        "        if print_all==True:\n",
        "            print(int(val), count)\n",
        "        class_hist.append((val,count))\n",
        "    if get_top_10 == True:\n",
        "        sorted_tuple = sorted(class_hist, key=lambda t: t[-1], reverse=True)[:(NUM_CLASSES + 1)]    #+1 because we are going to remove \"backround_google\" i.e. 4\n",
        "        class_list = [x for x,y in sorted_tuple]\n",
        "    return class_list\n",
        "\n",
        "def filter_fn(x, allowed_classes:list):\n",
        "    allowed_classes = tf.constant(allowed_classes)\n",
        "    isallowed = tf.equal(allowed_classes, tf.cast(x, allowed_classes.dtype))\n",
        "    reduced_sum = tf.reduce_sum(tf.cast(isallowed, tf.float32))\n",
        "    return tf.greater(reduced_sum, tf.constant(0.))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2fLIbNS2PDZ1"
      },
      "outputs": [],
      "source": [
        "#ds_train = tfds.load(DataSet, split='train + test[:75%]', as_supervised=True)\n",
        "if DataSet == 'caltech101':\n",
        "    ds_train, train_info = tfds.load(DataSet, split='train + test[:75%]', as_supervised=True, with_info = True)\n",
        "else:\n",
        "    ds_train, train_info = tfds.load(DataSet, split='train', as_supervised=True, with_info = True)\n",
        "ds_test = tfds.load(DataSet, split='test', as_supervised=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "QOoGq7JtPGn8",
        "outputId": "9e5deb0f-198f-4e98-9520-77fc62b54b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['airplane',\n",
              " 'automobile',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck']"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "class_list = num_samples_per_class(ds_train, get_top_10=True)\n",
        "if DataSet == 'caltech101':\n",
        "  class_list = [i for i in class_list if i != train_info.features['label'].str2int('background_google')]\n",
        "  class_list.sort()\n",
        "\n",
        "\"\"\"for name in train_info.features['label'].names:\n",
        "    print(name, train_info.features['label'].str2int(name))\n",
        "\"\"\"\n",
        "\n",
        "class_names = [train_info.features['label'].int2str(i) for i in class_list]\n",
        "display(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VeThcLypHU4m"
      },
      "outputs": [],
      "source": [
        "resized_ds_train = ds_train.filter(lambda x, y: filter_fn(y, class_list)) # as_supervised\n",
        "resized_ds_test = ds_test.filter(lambda x, y: filter_fn(y, class_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DApyIbKhPISb",
        "outputId": "0734cf72-b56f-4a7f-fd42-3e21ce1fb3d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 5000\n",
            "1 5000\n",
            "2 5000\n",
            "3 5000\n",
            "4 5000\n",
            "5 5000\n",
            "6 5000\n",
            "7 5000\n",
            "8 5000\n",
            "9 5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "num_samples_per_class(resized_ds_train, print_all=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8z2tJJ3PLsE",
        "outputId": "075fc680-5cc4-4c55-9275-ab8c0a0e5014"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1000\n",
            "1 1000\n",
            "2 1000\n",
            "3 1000\n",
            "4 1000\n",
            "5 1000\n",
            "6 1000\n",
            "7 1000\n",
            "8 1000\n",
            "9 1000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "num_samples_per_class(resized_ds_test, print_all=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QdPKLGVdPNrk"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "if DataSet=='caltech101':\n",
        "    IMG_SIZE = 60\n",
        "elif DataSet=='cifar10':\n",
        "    IMG_SIZE = 32\n",
        "NUM_CHANNELS = 3\n",
        "BATCH_SIZE=128\n",
        "\n",
        "input_shape = (IMG_SIZE,IMG_SIZE,NUM_CHANNELS)\n",
        "#Relabelling to avoid issues. Note that human readability is reduced by this\n",
        "table = tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=tf.constant(class_list, dtype=tf.int64),\n",
        "        #values=tf.constant([tfutils.to_categorical(0, num_classes=NUM_CLASSES, dtype=np.int64), tfutils.to_categorical(1, num_classes=NUM_CLASSES, dtype=np.int64), tfutils.to_categorical(2, num_classes=NUM_CLASSES, dtype=np.int64), tfutils.to_categorical(3, num_classes=NUM_CLASSES, dtype=np.int64), tfutils.to_categorical(4, num_classes=NUM_CLASSES, dtype=np.int64), tfutils.to_categorical(5, num_classes=NUM_CLASSES, dtype=np.int64), tfutils.to_categorical(6, num_classes=NUM_CLASSES, dtype=np.int64), tfutils.to_categorical(7, num_classes=NUM_CLASSES, dtype=np.int64), tfutils.to_categorical(8, num_classes=NUM_CLASSES, dtype=np.int64), tfutils.to_categorical(9, num_classes=NUM_CLASSES, dtype=np.int64)],  dtype=tf.int64),\n",
        "        values=tf.constant([0, 1, 2, 3, 4, 5, 6, 7, 8, 9],  dtype=tf.int64)\n",
        "    ),\n",
        "    default_value= tf.constant(0,  dtype=tf.int64)\n",
        ")\n",
        "\n",
        "#This function will be used in the graph execution hence @tf.function prefix\n",
        "@tf.function\n",
        "def map_func(label):\n",
        "    global class_list\n",
        "    global loss\n",
        "    mapped_label = table.lookup(label)\n",
        "    if loss != 'sparse_categorical_crossentropy':\n",
        "        mapped_label = tf.one_hot(indices=mapped_label, depth=NUM_CLASSES)\n",
        "    print(\"Label = \" + str(label) + \"\\t\" + \"Mapped Label = \" + str(mapped_label))\n",
        "    return mapped_label\n",
        "\n",
        "#Preprocessing done as part of the graph\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  layers.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "resize_layer = tf.keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "buffer_size = 30*NUM_CLASSES\n",
        "\n",
        "#Preprocessing function which invokes above graphs\n",
        "def prepare(ds, shuffle=False, augment=False, resize_only = False):\n",
        "    global buffer_size\n",
        "    global BATCH_SIZE\n",
        "    \n",
        "\n",
        "    # Resize and rescale all datasets.\n",
        "    if resize_only==True:\n",
        "        ds = ds.map(lambda x, y: (resize_layer(x), map_func(y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    else:\n",
        "        ds = ds.map(lambda x, y: (resize_and_rescale(x), map_func(y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    \n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size)\n",
        "        \n",
        "    # Batch all datasets.\n",
        "    #ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "    # Use data augmentation only on the training set.\n",
        "    if augment:\n",
        "        #f_ds = ds.filter(lambda x, y: filter_fn(y, [2,3,6]))    #[2,3,6] are the examples with lesser data. We are trying to bring back balance\n",
        "        #f_ds_aug = f_ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        #ds = ds.concatenate(f_ds_aug)\n",
        "        #ds_aug = ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        #ds = ds.concatenate(ds_aug)\n",
        "        ds_aug = ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        ds = ds.concatenate(ds_aug)\n",
        "\n",
        "        \n",
        "    # Use buffered prefetching on all datasets.\n",
        "    return ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmLFCHD6PgLw",
        "outputId": "e5f1a4c4-874e-4da1-9a60-b19482c674b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label = Tensor(\"label:0\", shape=(), dtype=int64)\tMapped Label = Tensor(\"one_hot:0\", shape=(10,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "resized_ds_train = prepare(resized_ds_train, augment=True)\n",
        "resized_ds_test = prepare(resized_ds_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "eBn0xUIRPizz",
        "outputId": "d122f01c-99fa-4209-e631-c7c4a480247d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=7>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "for example in resized_ds_train.take(1):\n",
        "  plt.imshow(example[0])\n",
        "  display((example[-1]))\n",
        "  display(tf.argmax(example[-1]))\n",
        "  #display(train_info.features['label'].int2str(example[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uf1KScmu9odE"
      },
      "outputs": [],
      "source": [
        "def num_samples_per_class_onehot(resized_ds_train, print_all=False):\n",
        "    if loss != 'sparse_categorical_crossentropy':\n",
        "        vals = np.unique(np.fromiter(resized_ds_train.map(lambda x, y: tf.argmax(y)), int), return_counts=True)\n",
        "    else:\n",
        "        vals = np.unique(np.fromiter(resized_ds_train.map(lambda x, y: y), int), return_counts=True)\n",
        "    class_list = []\n",
        "    class_hist = []\n",
        "    for val,count in zip(*vals):\n",
        "        if print_all==True:\n",
        "            print(int(val), count)\n",
        "        class_hist.append((val,count))\n",
        "    class_hist.sort()\n",
        "    return class_hist\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "avZ2eG0Ty3fi",
        "outputId": "16257347-db37-489d-beef-80e70366b804"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[(0, 10000),\n",
              " (1, 10000),\n",
              " (2, 10000),\n",
              " (3, 10000),\n",
              " (4, 10000),\n",
              " (5, 10000),\n",
              " (6, 10000),\n",
              " (7, 10000),\n",
              " (8, 10000),\n",
              " (9, 10000)]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Post prepare function, all the labels will be converted to one hot encoders. In order to get class-wise distribution, we will need to convert each one hot encoder into its label (temporarily)\n",
        "#We need a new function to handle it\n",
        "class_hist = num_samples_per_class_onehot(resized_ds_train)\n",
        "display(class_hist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ftnZ5OyvQB98",
        "outputId": "70c5cb48-93d3-4023-beb7-273722cd41a2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'VGG based CadenceNet'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#reg = tf.keras.regularizers.L2(0.01)\n",
        "reg = tf.keras.regularizers.L1L2(l1 =0.0, l2 = 0.1)\n",
        "#reg = tf.keras.regularizers.L1L2(l1 =0.0, l2 = 0.0)\n",
        "#beta_regularizer = 0.1\n",
        "#gamma_regularizer = 0.1\n",
        "\n",
        "model = models.Sequential()\n",
        "kernel_size = (3,3)\n",
        "pool_size = (2,2)\n",
        "if USE_ORIGINAL == 1:\n",
        "\tdisplay(\"Original CadenceNet\")\n",
        "\t#model.add(resize_and_rescale)\n",
        "\t#model.add(data_augmentation)\n",
        "\tkernel_size = (5,5)\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, input_shape = input_shape, padding=\"same\", kernel_regularizer = reg))       #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tpool_size = (2,2)\n",
        "\tmodel.add(layers.MaxPool2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(.2))\n",
        "\n",
        "\tkernel_size = (3,3)\n",
        "\tmodel.add(layers.Conv2D(192, kernel_size, padding=\"same\", kernel_regularizer = reg))      #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "\tmodel.add(layers.BatchNormalization())                                                      #beta_regularizer = beta_regularizer, gamma_regularizer = gamma_regularizer\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tpool_size = (2,2)\n",
        "\tmodel.add(layers.MaxPool2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(.2))\n",
        "\t#model.add(layers.SpatialDropout2D(0.2))\n",
        "\t\n",
        "\tkernel_size = (3,3)\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, padding=\"same\", kernel_regularizer = reg))       #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tmodel.add(layers.Dropout(.2))\n",
        "\n",
        "\tkernel_size = (3,3)\n",
        "\tmodel.add(layers.Conv2D(128, kernel_size, padding=\"same\", kernel_regularizer = reg))      #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.ReLU())\n",
        "\tpool_size = (2,2)\n",
        "\tmodel.add(layers.MaxPool2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(.2))\n",
        "\t#model.add(layers.SpatialDropout2D(0.2))\n",
        "\n",
        "\tmodel.add(layers.Flatten())\n",
        "\tmodel.add(layers.Dropout(.2))\n",
        "\t#model.add(layers.Dense(NUM_CLASSES, activation='softmax', kernel_regularizer = reg))\n",
        "\tmodel.add(layers.Dense(NUM_CLASSES, kernel_regularizer = reg))\n",
        "\tmodel.add(layers.Softmax())\n",
        "else:\n",
        "\tdisplay(\"VGG based CadenceNet\")\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(32, kernel_size, activation='relu', kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same', input_shape=(IMG_SIZE, IMG_SIZE, NUM_CHANNELS)))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.Conv2D(32, kernel_size, activation='relu', kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.1))\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, activation='relu', kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.Conv2D(64, kernel_size, activation='relu', kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.2))\n",
        "\t\n",
        "\tmodel.add(layers.Conv2D(128, kernel_size, activation='relu', kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.Conv2D(128, kernel_size, activation='relu', kernel_initializer='he_uniform', kernel_regularizer = reg, padding='same'))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.MaxPooling2D(pool_size))\n",
        "\tmodel.add(layers.Dropout(0.3))\n",
        "\t\n",
        "\tmodel.add(layers.Flatten())\n",
        "\tmodel.add(layers.Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer = reg))\n",
        "\tmodel.add(layers.BatchNormalization())\n",
        "\tmodel.add(layers.Dropout(0.2))\n",
        "\tmodel.add(layers.Dense(NUM_CLASSES, kernel_regularizer = reg))\n",
        "\tmodel.add(layers.Softmax())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "B-aANPwedhNH"
      },
      "outputs": [],
      "source": [
        "def get_class_weights(class_hist):\n",
        "    \"\"\"\n",
        "    Returns the class weights as a tf.Tensor. Class weights are inverse of the class frequencies\n",
        "    Class frequencies are the number of samples of each class which we calculate in earlier steps\n",
        "    \"\"\"\n",
        "    inv_freq = tf.convert_to_tensor([1.0/count for label, count in class_hist], dtype=tf.float32)\n",
        "    return tfutils.normalize(inv_freq)\n",
        "\n",
        "\n",
        "def weightedloss(y_true, y_pred, gamma, class_weight):\n",
        "    \"\"\"\n",
        "    We assume that all arguments coming into this function are tf.Tensors type\n",
        "    class_weights are basically alpha in focal loss paper\n",
        "    \"\"\"\n",
        "    #ones = tf.convert_to_tensor(np.ones(shape=len(y_true)))\n",
        "    a = tf.math.multiply(tf.math.pow(tf.math.subtract(1.0, y_pred), gamma), tf.math.log(y_pred))  #((1-pt)^gamma)log(pt)\n",
        "    b = tf.math.multiply(-1.0, class_weight)                                                          #-alpha\n",
        "    b = tf.math.multiply(b,a)    \n",
        "    b = tf.math.multiply(b, y_true)\n",
        "    return b\n",
        "class WeightedLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, gamma, class_weight=np.ones(shape=NUM_CLASSES, dtype=np.float32)):\n",
        "        super().__init__()\n",
        "        self.gamma = tf.convert_to_tensor(gamma)\n",
        "        self.class_weight = tf.convert_to_tensor(class_weight, dtype=tf.float32)\n",
        "    def call(self, y_true, y_pred):\n",
        "        return weightedloss(y_true, y_pred, self.gamma, self.class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fHRlWtV83IeV"
      },
      "outputs": [],
      "source": [
        "Learning_Rate = 1e-5\n",
        "#tf.keras.optimizers.Adam(learning_rate=Learning_Rate)     #OR tf.keras.optimizers.SGD(learning_rate=Learning_Rate, momentum=0.9)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=Learning_Rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DHFaNgqtwZGz"
      },
      "outputs": [],
      "source": [
        "###EITHER\n",
        "\n",
        "#!pip install focal-loss\n",
        "#from focal_loss import SparseCategoricalFocalLoss \n",
        "#model.compile( optimizer = opt, loss = SparseCategoricalFocalLoss(gamma=2), metrics=['accuracy'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nFFBTJNwLAcA"
      },
      "outputs": [],
      "source": [
        "###OR\n",
        "model.compile( optimizer = opt, loss = loss, metrics=['accuracy'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pmqZtduVbl-2"
      },
      "outputs": [],
      "source": [
        "###OR\n",
        "#class_wts = get_class_weights(class_hist)\n",
        "#display(class_wts)\n",
        "#model.compile( optimizer = opt, loss = WeightedLoss(gamma=2.0, class_weight=class_wts), metrics=['accuracy'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HL7YFZKvbn92"
      },
      "outputs": [],
      "source": [
        "#model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNi4QKkp27-d",
        "outputId": "535dc50d-bf3b-4e87-e980-182f8695e635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "782/782 [==============================] - 51s 55ms/step - loss: 112.4044 - accuracy: 0.1574 - val_loss: 104.1069 - val_accuracy: 0.2308\n",
            "Epoch 2/80\n",
            "782/782 [==============================] - 44s 57ms/step - loss: 97.3657 - accuracy: 0.2238 - val_loss: 90.1137 - val_accuracy: 0.2901\n",
            "Epoch 3/80\n",
            "782/782 [==============================] - 41s 53ms/step - loss: 84.1183 - accuracy: 0.2602 - val_loss: 77.7017 - val_accuracy: 0.3283\n",
            "Epoch 4/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 72.3460 - accuracy: 0.2889 - val_loss: 66.6666 - val_accuracy: 0.3551\n",
            "Epoch 5/80\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 61.8755 - accuracy: 0.3140 - val_loss: 56.8824 - val_accuracy: 0.3668\n",
            "Epoch 6/80\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 52.6260 - accuracy: 0.3362 - val_loss: 48.2973 - val_accuracy: 0.3727\n",
            "Epoch 7/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 44.5699 - accuracy: 0.3582 - val_loss: 40.8979 - val_accuracy: 0.3695\n",
            "Epoch 8/80\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 37.6713 - accuracy: 0.3778 - val_loss: 34.6316 - val_accuracy: 0.3701\n",
            "Epoch 9/80\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 31.8676 - accuracy: 0.3980 - val_loss: 29.4123 - val_accuracy: 0.3731\n",
            "Epoch 10/80\n",
            "782/782 [==============================] - 43s 56ms/step - loss: 27.0665 - accuracy: 0.4163 - val_loss: 25.1073 - val_accuracy: 0.3805\n",
            "Epoch 11/80\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 23.1327 - accuracy: 0.4359 - val_loss: 21.6113 - val_accuracy: 0.3856\n",
            "Epoch 12/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 19.9395 - accuracy: 0.4546 - val_loss: 18.7884 - val_accuracy: 0.3960\n",
            "Epoch 13/80\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 17.3540 - accuracy: 0.4702 - val_loss: 16.4672 - val_accuracy: 0.4137\n",
            "Epoch 14/80\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 15.2501 - accuracy: 0.4865 - val_loss: 14.5859 - val_accuracy: 0.4206\n",
            "Epoch 15/80\n",
            "782/782 [==============================] - 44s 57ms/step - loss: 13.5252 - accuracy: 0.5029 - val_loss: 13.0303 - val_accuracy: 0.4287\n",
            "Epoch 16/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 12.0937 - accuracy: 0.5156 - val_loss: 11.7422 - val_accuracy: 0.4389\n",
            "Epoch 17/80\n",
            "782/782 [==============================] - 43s 54ms/step - loss: 10.8965 - accuracy: 0.5307 - val_loss: 10.6593 - val_accuracy: 0.4432\n",
            "Epoch 18/80\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 9.8892 - accuracy: 0.5431 - val_loss: 9.7375 - val_accuracy: 0.4554\n",
            "Epoch 19/80\n",
            "782/782 [==============================] - 43s 56ms/step - loss: 9.0329 - accuracy: 0.5573 - val_loss: 8.9533 - val_accuracy: 0.4603\n",
            "Epoch 20/80\n",
            "782/782 [==============================] - 43s 54ms/step - loss: 8.3001 - accuracy: 0.5706 - val_loss: 8.2885 - val_accuracy: 0.4683\n",
            "Epoch 21/80\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 7.6699 - accuracy: 0.5800 - val_loss: 7.7041 - val_accuracy: 0.4727\n",
            "Epoch 22/80\n",
            "782/782 [==============================] - 43s 54ms/step - loss: 7.1202 - accuracy: 0.5903 - val_loss: 7.2246 - val_accuracy: 0.4688\n",
            "Epoch 23/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 6.6392 - accuracy: 0.6014 - val_loss: 6.7618 - val_accuracy: 0.4825\n",
            "Epoch 24/80\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 6.2137 - accuracy: 0.6089 - val_loss: 6.3830 - val_accuracy: 0.4855\n",
            "Epoch 25/80\n",
            "782/782 [==============================] - 43s 56ms/step - loss: 5.8371 - accuracy: 0.6160 - val_loss: 6.0288 - val_accuracy: 0.4900\n",
            "Epoch 26/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 5.4938 - accuracy: 0.6287 - val_loss: 5.7344 - val_accuracy: 0.4881\n",
            "Epoch 27/80\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 5.1923 - accuracy: 0.6353 - val_loss: 5.4297 - val_accuracy: 0.5035\n",
            "Epoch 28/80\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 4.9202 - accuracy: 0.6431 - val_loss: 5.1710 - val_accuracy: 0.5074\n",
            "Epoch 29/80\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 4.6731 - accuracy: 0.6506 - val_loss: 4.9675 - val_accuracy: 0.5021\n",
            "Epoch 30/80\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 4.4486 - accuracy: 0.6565 - val_loss: 4.7247 - val_accuracy: 0.5177\n",
            "Epoch 31/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 4.2406 - accuracy: 0.6647 - val_loss: 4.5599 - val_accuracy: 0.5150\n",
            "Epoch 32/80\n",
            "782/782 [==============================] - 42s 53ms/step - loss: 4.0518 - accuracy: 0.6722 - val_loss: 4.3772 - val_accuracy: 0.5155\n",
            "Epoch 33/80\n",
            "782/782 [==============================] - 41s 53ms/step - loss: 3.8791 - accuracy: 0.6776 - val_loss: 4.2121 - val_accuracy: 0.5198\n",
            "Epoch 34/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 3.7213 - accuracy: 0.6828 - val_loss: 4.0718 - val_accuracy: 0.5260\n",
            "Epoch 35/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 3.5719 - accuracy: 0.6903 - val_loss: 3.9054 - val_accuracy: 0.5404\n",
            "Epoch 36/80\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 3.4379 - accuracy: 0.6949 - val_loss: 3.7553 - val_accuracy: 0.5539\n",
            "Epoch 37/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 3.3111 - accuracy: 0.7003 - val_loss: 3.6575 - val_accuracy: 0.5465\n",
            "Epoch 38/80\n",
            "782/782 [==============================] - 43s 54ms/step - loss: 3.1967 - accuracy: 0.7051 - val_loss: 3.5781 - val_accuracy: 0.5408\n",
            "Epoch 39/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 3.0894 - accuracy: 0.7113 - val_loss: 3.4489 - val_accuracy: 0.5581\n",
            "Epoch 40/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 2.9915 - accuracy: 0.7133 - val_loss: 3.3786 - val_accuracy: 0.5501\n",
            "Epoch 41/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 2.8930 - accuracy: 0.7200 - val_loss: 3.2817 - val_accuracy: 0.5588\n",
            "Epoch 42/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 2.8067 - accuracy: 0.7243 - val_loss: 3.1890 - val_accuracy: 0.5655\n",
            "Epoch 43/80\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 2.7277 - accuracy: 0.7273 - val_loss: 3.1186 - val_accuracy: 0.5687\n",
            "Epoch 44/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 2.6488 - accuracy: 0.7325 - val_loss: 3.0248 - val_accuracy: 0.5779\n",
            "Epoch 45/80\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 2.5777 - accuracy: 0.7372 - val_loss: 2.9971 - val_accuracy: 0.5656\n",
            "Epoch 46/80\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 2.5142 - accuracy: 0.7388 - val_loss: 2.9123 - val_accuracy: 0.5759\n",
            "Epoch 47/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 2.4481 - accuracy: 0.7435 - val_loss: 2.8475 - val_accuracy: 0.5784\n",
            "Epoch 48/80\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 2.3904 - accuracy: 0.7474 - val_loss: 2.8039 - val_accuracy: 0.5796\n",
            "Epoch 49/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 2.3322 - accuracy: 0.7508 - val_loss: 2.7222 - val_accuracy: 0.5961\n",
            "Epoch 50/80\n",
            "782/782 [==============================] - 43s 54ms/step - loss: 2.2799 - accuracy: 0.7540 - val_loss: 2.6483 - val_accuracy: 0.6062\n",
            "Epoch 51/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 2.2300 - accuracy: 0.7576 - val_loss: 2.5985 - val_accuracy: 0.6085\n",
            "Epoch 52/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 2.1845 - accuracy: 0.7597 - val_loss: 2.5706 - val_accuracy: 0.6032\n",
            "Epoch 53/80\n",
            "782/782 [==============================] - 43s 56ms/step - loss: 2.1382 - accuracy: 0.7630 - val_loss: 2.5573 - val_accuracy: 0.5962\n",
            "Epoch 54/80\n",
            "782/782 [==============================] - 45s 57ms/step - loss: 2.0994 - accuracy: 0.7643 - val_loss: 2.4696 - val_accuracy: 0.6141\n",
            "Epoch 55/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 2.0581 - accuracy: 0.7669 - val_loss: 2.4646 - val_accuracy: 0.6060\n",
            "Epoch 56/80\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 2.0185 - accuracy: 0.7718 - val_loss: 2.4108 - val_accuracy: 0.6130\n",
            "Epoch 57/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 1.9844 - accuracy: 0.7715 - val_loss: 2.3633 - val_accuracy: 0.6229\n",
            "Epoch 58/80\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 1.9470 - accuracy: 0.7762 - val_loss: 2.3744 - val_accuracy: 0.6080\n",
            "Epoch 59/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 1.9144 - accuracy: 0.7788 - val_loss: 2.3261 - val_accuracy: 0.6177\n",
            "Epoch 60/80\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 1.8816 - accuracy: 0.7791 - val_loss: 2.2863 - val_accuracy: 0.6215\n",
            "Epoch 61/80\n",
            "782/782 [==============================] - 43s 54ms/step - loss: 1.8532 - accuracy: 0.7818 - val_loss: 2.2812 - val_accuracy: 0.6205\n",
            "Epoch 62/80\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 1.8263 - accuracy: 0.7837 - val_loss: 2.2359 - val_accuracy: 0.6245\n",
            "Epoch 63/80\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 1.7935 - accuracy: 0.7868 - val_loss: 2.2315 - val_accuracy: 0.6231\n",
            "Epoch 64/80\n",
            "782/782 [==============================] - 43s 54ms/step - loss: 1.7698 - accuracy: 0.7891 - val_loss: 2.1505 - val_accuracy: 0.6396\n",
            "Epoch 65/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 1.7437 - accuracy: 0.7889 - val_loss: 2.1646 - val_accuracy: 0.6311\n",
            "Epoch 66/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 1.7161 - accuracy: 0.7930 - val_loss: 2.1602 - val_accuracy: 0.6207\n",
            "Epoch 67/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 1.6935 - accuracy: 0.7947 - val_loss: 2.0850 - val_accuracy: 0.6443\n",
            "Epoch 68/80\n",
            "782/782 [==============================] - 43s 56ms/step - loss: 1.6691 - accuracy: 0.7957 - val_loss: 2.0625 - val_accuracy: 0.6458\n",
            "Epoch 69/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 1.6443 - accuracy: 0.7991 - val_loss: 2.0519 - val_accuracy: 0.6442\n",
            "Epoch 70/80\n",
            "782/782 [==============================] - 43s 56ms/step - loss: 1.6247 - accuracy: 0.7993 - val_loss: 2.0895 - val_accuracy: 0.6254\n",
            "Epoch 71/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 1.6056 - accuracy: 0.8015 - val_loss: 2.0336 - val_accuracy: 0.6422\n",
            "Epoch 72/80\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 1.5843 - accuracy: 0.8024 - val_loss: 1.9793 - val_accuracy: 0.6522\n",
            "Epoch 73/80\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 1.5635 - accuracy: 0.8043 - val_loss: 1.9937 - val_accuracy: 0.6409\n",
            "Epoch 74/80\n",
            "782/782 [==============================] - 43s 54ms/step - loss: 1.5448 - accuracy: 0.8055 - val_loss: 1.9589 - val_accuracy: 0.6464\n",
            "Epoch 75/80\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 1.5276 - accuracy: 0.8067 - val_loss: 1.9330 - val_accuracy: 0.6505\n",
            "Epoch 76/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 1.5094 - accuracy: 0.8087 - val_loss: 1.9788 - val_accuracy: 0.6317\n",
            "Epoch 77/80\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 1.4912 - accuracy: 0.8105 - val_loss: 1.9372 - val_accuracy: 0.6418\n",
            "Epoch 78/80\n",
            "782/782 [==============================] - 42s 54ms/step - loss: 1.4758 - accuracy: 0.8101 - val_loss: 1.9058 - val_accuracy: 0.6497\n",
            "Epoch 79/80\n",
            "782/782 [==============================] - 43s 54ms/step - loss: 1.4582 - accuracy: 0.8128 - val_loss: 1.9077 - val_accuracy: 0.6431\n",
            "Epoch 80/80\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 1.4447 - accuracy: 0.8144 - val_loss: 1.9080 - val_accuracy: 0.6387\n"
          ]
        }
      ],
      "source": [
        "#h = model.fit( resized_ds_train, epochs=10)\n",
        "resized_ds_train = resized_ds_train.batch(BATCH_SIZE)\n",
        "resized_ds_test_unbatched = resized_ds_test\n",
        "resized_ds_test = resized_ds_test.batch(BATCH_SIZE)\n",
        "\n",
        "h = model.fit( resized_ds_train, epochs=80, validation_data = resized_ds_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FuOyiBsTQkYL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "79d39d5a-760a-482d-9558-989beb9335ff"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxc9Xnv8c8zi3bJ1uJFtmxksME2i22wHVOWEiCEQALchq0lhOzNvbRJ2qQtSZqmzW176U1v06TNUiehgYQQqAkEUggBAiQQNtlgvAG2sYxlW9ZiW5ZlS5rluX+cIyGIbbxIc0aa7/v1mtecOcvMo5mRvjq/3zm/Y+6OiIgIQCzqAkREJH8oFEREZJBCQUREBikURERkkEJBREQGKRRERGSQQkHkKJjZD8zs7w9z3WYzu/BYn0ckFxQKIiIySKEgIiKDFAoyZoXNNn9hZi+ZWY+Zfd/MJpnZg2bWbWaPmFn1kPUvM7M1ZrbbzB43szlDli0wsxXhdncCJW95rfea2Yvhtr81s9OOsuaPm9kGM9tpZveZ2ZRwvpnZ18yszcz2mNkqMzslXHaJma0Na9tqZp87qjdMBIWCjH3vB94FnAi8D3gQ+AIwgeD7/ykAMzsRuAP4TLjsAeB+MysysyLgXuCHQA3wX+HzEm67ALgF+GOgFvgP4D4zKz6SQs3sfOD/AFcD9cBm4Cfh4ouAc8OfY1y4Tme47PvAH7t7JXAK8KsjeV2RoRQKMtb9m7vvcPetwG+AZ939BXfvBe4BFoTrXQP8t7s/7O4p4J+BUuD3gCVAEvhXd0+5+zLg+SGv8QngP9z9WXfPuPutQF+43ZG4DrjF3Ve4ex/weeBMM2sEUkAlMBswd1/n7tvD7VLAXDOrcvdd7r7iCF9XZJBCQca6HUOm9x/gcUU4PYXgP3MA3D0LbAGmhsu2+ptHj9w8ZPo44LNh09FuM9sNTAu3OxJvrWEvwd7AVHf/FfDvwDeBNjNbamZV4arvBy4BNpvZE2Z25hG+rsgghYJIYBvBH3cgaMMn+MO+FdgOTA3nDZg+ZHoL8A/uPn7Irczd7zjGGsoJmqO2Arj7N9z9DGAuQTPSX4Tzn3f3y4GJBM1cdx3h64oMUiiIBO4CLjWzC8wsCXyWoAnot8DTQBr4lJklzewPgMVDtv0u8Ekze0fYIVxuZpeaWeUR1nAH8GEzmx/2R/wjQXNXs5ktCp8/CfQAvUA27PO4zszGhc1ee4DsMbwPUuAUCiKAu78CfAD4N6CDoFP6fe7e7+79wB8AHwJ2EvQ//HTItk3Axwmad3YBG8J1j7SGR4AvAXcT7J2cAFwbLq4iCJ9dBE1MncBXw2XXA81mtgf4JEHfhMhRMV1kR0REBmhPQUREBikURERkkEJBREQGKRRERGRQIuoCjkVdXZ03NjZGXYaIyKiyfPnyDnefcKBlozoUGhsbaWpqiroMEZFRxcw2H2yZmo9ERGSQQkFERAYpFEREZNCo7lMQETkaqVSKlpYWent7oy5lRJWUlNDQ0EAymTzsbRQKIlJwWlpaqKyspLGxkTcPfjt2uDudnZ20tLQwY8aMw95OzUciUnB6e3upra0ds4EAYGbU1tYe8d6QQkFECtJYDoQBR/MzFmQoNDXv5J9+8TIaIVZE5M0KMhRWbe3i249vpGNvf9SliEgB2r17N9/61reOeLtLLrmE3bt3j0BFbyjIUGisKwdgc2dPxJWISCE6WCik0+lDbvfAAw8wfvz4kSoLKNBQmFEbhMKmDoWCiOTeTTfdxMaNG5k/fz6LFi3inHPO4bLLLmPu3LkAXHHFFZxxxhmcfPLJLF26dHC7xsZGOjo6aG5uZs6cOXz84x/n5JNP5qKLLmL//v3DUltBHpI6tbqUeMxo1p6CSMH7u/vXsHbbnmF9zrlTqvjy+04+6PKbb76Z1atX8+KLL/L4449z6aWXsnr16sFDR2+55RZqamrYv38/ixYt4v3vfz+1tbVveo7169dzxx138N3vfperr76au+++mw984APHXHtBhkIyHmNadSnNHfuiLkVEhMWLF7/pXIJvfOMb3HPPPQBs2bKF9evX/04ozJgxg/nz5wNwxhln0NzcPCy1FGQoQNCvoOYjETnUf/S5Ul5ePjj9+OOP88gjj/D0009TVlbGeeedd8BzDYqLiwen4/H4sDUfFWSfAkBjbTmbO3t0WKqI5FxlZSXd3d0HXNbV1UV1dTVlZWW8/PLLPPPMMzmtrWD3FGbUldPTn6F9bx8TK0uiLkdECkhtbS1nnXUWp5xyCqWlpUyaNGlw2cUXX8x3vvMd5syZw0knncSSJUtyWlvBhsJxtWUANHfsUyiISM79+Mc/PuD84uJiHnzwwQMuG+g3qKurY/Xq1YPzP/e5zw1bXQXbfDQjPFehWf0KIiKDCjYUpo4vJREzNumwVBGRQQUbCol4jOk1ZTqrWURkiIINBRg4LFXnKoiIDCjsUNBhqSIib1KYobD6bvjBe2msLWFff4a27r6oKxIRyQuFGQp93dD8G04qDcY70ZnNIpLPKioqcvZahRkKtbMAOJ6tgIbQFhEZUJgnr9WdCEBt72aK4jPU2SwiOXXTTTcxbdo0brzxRgD+9m//lkQiwWOPPcauXbtIpVL8/d//PZdffnnOayvMUCivg5LxxDo3MK1mrk5gEylkD94ErauG9zknnwrvufmgi6+55ho+85nPDIbCXXfdxUMPPcSnPvUpqqqq6OjoYMmSJVx22WU5v5b0iDUfmdktZtZmZquHzKsxs4fNbH14Xx3ONzP7hpltMLOXzOz0kaorLATqZkHHqzTWluu6CiKSUwsWLKCtrY1t27axcuVKqqurmTx5Ml/4whc47bTTuPDCC9m6dSs7duzIeW0juafwA+DfgduGzLsJeNTdbzazm8LHfwW8B5gV3t4BfDu8Hzl1J8LGX9F4UjlPbewgm3VisdwmsojkgUP8Rz+SrrrqKpYtW0ZrayvXXHMNt99+O+3t7SxfvpxkMkljY+MBh8weaSO2p+DuvwZ2vmX25cCt4fStwBVD5t/mgWeA8WZWP1K1AVA7E7q3M2u805vK6rBUEcmpa665hp/85CcsW7aMq666iq6uLiZOnEgymeSxxx5j8+bNkdSV66OPJrn79nC6FRgYL3YqsGXIei3hvN9hZp8wsyYza2pvbz/6SsLO5tmJYPdMh6WKSC6dfPLJdHd3M3XqVOrr67nuuutoamri1FNP5bbbbmP27NmR1BVZR7O7u5kd8anE7r4UWAqwcOHCoz8VuS44LHW6twC1NHf2cOYJtYfeRkRkGK1a9UYHd11dHU8//fQB19u7d2+uSsr5nsKOgWah8L4tnL8VmDZkvYZw3sipngEWp7pnM0WJmI5AEhEh96FwH3BDOH0D8LMh8z8YHoW0BOga0sw0MhJFUDMD27me6TVlaj4SEWEEm4/M7A7gPKDOzFqALwM3A3eZ2UeBzcDV4eoPAJcAG4B9wIdHqq43qZ0FHet1WKpIAXL3nJ8DkGtHM9jniIWCu//hQRZdcIB1HbhxpGo5qLpZsPFXzDyuhF+vbyedyZKIF+bIHyKFpKSkhM7OTmpra8dsMLg7nZ2dlJQc2eWGC/OM5gF1syDTx2kVe+hPZ9mya//gZTpFZOxqaGigpaWFYzqCcRQoKSmhoaHhiLYp8FAIDks9KdkKFLOhba9CQaQAJJNJZsyYEXUZeamw20rC0VKnplsAWN/WHWU1IiKRK+xQKK+F0hpKujZSP66EDTtydyywiEg+KuxQgKAJqWMDMydWsL5NoSAihU2hUDcTOl5l1sRKNrTtJZvV9ZpFpHApFOpOhJ425lRn2Z/KsK1rf9QViYhERqEQdjafXBwMjKcmJBEpZAqF8LDU47LBUEvqbBaRQqZQqD4OYgnKuzdRV1Gsw1JFpKApFOJJqDkeOl5l5sRyNR+JSEFTKEB4WOr6wSOQjmYQKRGRsUChAEEo7NzISROK6e5N69KcIlKwFAoAk06GbJpTioNr/qxXZ7OIFCiFAsDEOQDMyDYDGgNJRAqXQgGCcxViCar2bGBcaVKdzSJSsBQKEFyas+5ErG0tsyZWsEGhICIFSqEwYOIcaFvLrEkKBREpXAqFARPnwu7XmV1t7Ozpp3OvjkASkcKjUBgwcS4ApxVtAzQGkogUJoXCgElBKMzIvg4oFESkMCkUBoybDkUVjOt+lfKiOBsVCiJSgBQKA2IxmDAba1vHzEmVvNKqcxVEpPAoFIaaNBfa1jJ7YgUvt+7RGEgiUnAUCkNNnAv7OllQm2LXvhQ79ugIJBEpLAqFocIjkOYVBRfcWbd9T5TViIjknEJhqEknA9CY3QzAWoWCiBSYSELBzP7MzNaY2Wozu8PMSsxshpk9a2YbzOxOMyvKeWHldVA+gdJdrzB1fKn2FESk4OQ8FMxsKvApYKG7nwLEgWuBfwK+5u4zgV3AR3NdGxA0Ie1Yy5z6KoWCiBScqJqPEkCpmSWAMmA7cD6wLFx+K3BFJJVNnAvtLzN3cjmbOnroTWUiKUNEJAo5DwV33wr8M/A6QRh0AcuB3e6eDldrAaYeaHsz+4SZNZlZU3t7+/AXOGkupPZxRtUeso7OVxCRghJF81E1cDkwA5gClAMXH+727r7U3Re6+8IJEyYMf4ETg87m2fEWQEcgiUhhiaL56EJgk7u3u3sK+ClwFjA+bE4CaAC2RlAbTDgpuNu3kfKiuEJBRApKFKHwOrDEzMrMzIALgLXAY8CV4To3AD+LoDYoroDqRmLtazlpciXrtqv5SEQKRxR9Cs8SdCivAFaFNSwF/gr4czPbANQC3891bYMmnQKtq4MjkDTchYgUkEiOPnL3L7v7bHc/xd2vd/c+d3/N3Re7+0x3v8rdoxtjon4edG7g1AlxunvTtOzaH1kpIiK5pDOaD6R+PuAsSG4B1NksIoVDoXAg9fMAaExtwAz1K4hIwVAoHEjlJKiYTHH7Ko6rKdOegogUDIXCwdTPg+0rBzubRUQKgULhYOrnQfvLnDqxiM2d+9jbl377bURERjmFwsHUzwPPsrB0GwCvaG9BRAqAQuFgpswHYFZmIwBr1dksIgVAoXAwVVOhrJbxXWupKkmwdpv2FERk7FMoHIwZ1M/Dtq/k1IZxrNq6O+qKRERGnELhUOrnQds6Fkwp4+Xt3bq2goiMeQqFQ6mfB9kUv1e5g3TWdb6CiIx5CoVDCc9snkMzAKu2dkVYjIjIyFMoHEr1DCgex/jda6mrKGLlFoWCiIxtCoVDMYP607DWlZzWMJ6XWtTZLCJjm0Lh7dTPg9bVzJ9Szob2vTqzWUTGNIXC26mfD5k+llR14A6r1a8gImOYQuHthJ3Nc9kEoCYkERnTFApvp/YESJZTsXM1U8eXsrJFewoiMnYpFN5OLA5TFkBLE/OmjdOegoiMaQqFwzFtEbS+xIL6Erbs3M/Onv6oKxIRGREKhcPRsAiyaZaUBtds1t6CiIxVCoXD0bAYgFn96zCDl9SvICJjlELhcFRMgOpGSlqXc3xdufYURGTMUigcroZFsOV5Tps6TnsKIjJmKRQOV8Ni2NvKmXX7aevuo7WrN+qKRESGnULhcDUsBGBhIrg850o1IYnIGBRJKJjZeDNbZmYvm9k6MzvTzGrM7GEzWx/eV0dR20FNPhUSJUzft5pk3Fjx+q6oKxIRGXZR7Sl8HfiFu88G5gHrgJuAR919FvBo+Dh/xJMwZQGJbcs5Zeo4ljcrFERk7Ml5KJjZOOBc4PsA7t7v7ruBy4Fbw9VuBa7IdW1vq2ERbF/JkukVvNTSpctzisiYc1ihYGafNrMqC3zfzFaY2UVH+ZozgHbgP83sBTP7npmVA5PcfXu4Tisw6Siff+RMWwyZfs6r2kZ/JqsRU0VkzDncPYWPuPse4CKgGrgeuPkoXzMBnA58290XAD28panI3R3wA21sZp8wsyYza2pvbz/KEo5SwyIATsm+CsDzakISkTHmcEPBwvtLgB+6+5oh845UC9Di7s+Gj5cRhMQOM6sHCO/bDrSxuy9194XuvnDChAlHWcJRqpwM46ZT3raC4yeU09S8M7evLyIywg43FJab2S8JQuEhM6sEskfzgu7eCmwxs5PCWRcAa4H7gBvCeTcAPzua5x9xDQuhpYlFx9XQtHkX2ewBd2hEREalww2FjxI08Sxy931AEvjwMbzunwK3m9lLwHzgHwmao95lZuuBCzn65qmRNW0x7Gnh7En9dO1PsaF9b9QViYgMm8Rhrncm8KK795jZBwiae75+tC/q7i8CCw+w6IKjfc6cCfsV3pHcCFTQ1LyLEydVRluTiMgwOdw9hW8D+8xsHvBZYCNw24hVlc8mnwaJUibsWkFdRZH6FURkTDncUEiHRwRdDvy7u38TKMx/jxNFMG0x1vwkC4+r4fnNCgURGTsONxS6zezzBIei/reZxQj6FQpT4zmwYzVnTTW27NyvwfFEZMw43FC4BugjOF+hFWgAvjpiVeW7GecAcE7yFQCatLcgImPEYYVCGAS3A+PM7L1Ar7sXZp8CwJTTIVnGtD0rKE3GadJJbCIyRhzuMBdXA88BVwFXA8+a2ZUjWVheSxTBtHcQ3/wkC6aP53l1NovIGHG4zUdfJDhH4QZ3/yCwGPjSyJU1CjSeDW1rOWcKrNu+h7196agrEhE5ZocbCjF3HzrsROcRbDs2zTgXgN8vfpWsw/LNakISkdHvcP+w/8LMHjKzD5nZh4D/Bh4YubJGgSkLIFnOrP0vkowbv93QEXVFIiLH7LDOaHb3vzCz9wNnhbOWuvs9I1fWKBBPwvQlJF9/itOnX8WTCgURGQMOuwnI3e929z8Pb4UdCAMaz4b2l3nX9Bhrtu2hc29f1BWJiByTQ4aCmXWb2Z4D3LrNbE+uisxbYb/CBaXB9RWe2tgZZTUiIsfskKHg7pXuXnWAW6W7V+WqyLxVPw+KKjhu7wtUliR4cn2OL/ojIjLMCvsIomMVT8L0M4k1/4bfO6GWJ9d3EAwRJSIyOikUjlXj2dDxKhdON7Z19bKpoyfqikREjppC4ViF/QrnJdYC6CgkERnVFArHqn4+lNVR1/oEDdWlPLleoSAio5dC4VjFYjDrXdiGRzjnhGqe3thJOnNUl68WEYmcQmE4zLoI9u/ivbVb6e5Ls7KlK+qKRESOikJhOJxwPlic03ufwwyeUr+CiIxSCoXhUDoepi+htPlRTp5SpX4FERm1FArDZdZFsGM175mWZcXruzSUtoiMSgqF4XLiuwG4uHgV6azr7GYRGZUUCsNlwmwYN50Zu55kfFmSh9bsiLoiEZEjplAYLmZw4kXENj3Bu08cz6PrdpDSoakiMsooFIbTrHdDah9XTdjMnt40z23StZtFZHRRKAynGedAooT5+5+jJBnjoTWtUVckInJEIgsFM4ub2Qtm9vPw8Qwze9bMNpjZnWZWFFVtRy1ZCjPOJbHxl5w7s45frtmhUVNFZFSJck/h08C6IY//Cfiau88EdgEfjaSqYzXrItjVzPuP66F1Ty+rtursZhEZPSIJBTNrAC4Fvhc+NuB8YFm4yq3AFVHUdszmvA8wzu37DfGY8UsdhSQio0hUewr/CvwlMHB4Ti2w290HzvhqAaYeaEMz+4SZNZlZU3t7Hp4LUDkZGs+m9NV7WXxctfoVRGRUyXkomNl7gTZ3X34027v7Undf6O4LJ0yYMMzVDZNTr4TODVw7fTfr2/byWvveqCsSETksUewpnAVcZmbNwE8Imo2+Dow3s0S4TgOwNYLahsecyyCW4Pz0rwF4eK2akERkdMh5KLj75929wd0bgWuBX7n7dcBjwJXhajcAP8t1bcOmrAZOOJ/KDfdzSn2FmpBEZNTIp/MU/gr4czPbQNDH8P2I6zk2p1wJXVu4YXo7K17fzdbd+6OuSETkbUUaCu7+uLu/N5x+zd0Xu/tMd7/K3fuirO2Yzb4EEiVc7E8BcM+KlogLEhF5e/m0pzC2FFfCie+mcuP9nNk4jrtXbNWJbCKS9xQKI+mU90NPO3983DY2dfSw4vVdUVckInJICoWRNOsiKKrkrN4nKE3GWbZ89B5QJSKFQaEwkpKlMPtSkq/cz2Vzq/n5S9voTWWirkpE5KAUCiNt/h9BbxcfrV1Jd2+aX+qcBRHJYwqFkTbjXKidxazNdzJlXAl3L9dRSCKSvxQKI80MFn0M29rE/zyxm9+sb2fHnt6oqxIROSCFQi7MuxaSZVyR+QVZh3teUIeziOQnhUIulI6HU6+i8tV7OXdagruatpDN6pwFEck/CoVcWfQxSO/nc5OW81p7D0+8mofDfotIwVMo5Er9adCwmFO3LaO+sojv/ua1qCsSEfkdCoVcWvQxbOdGvji3nd9u7GS1LtUpInlGoZBLcy+Hslreve9+yovifE97CyKSZxQKuZQsgTM+THL9g/zpqWl+/tJ2tmlIbRHJIwqFXDvzRigq54P9d+LAD37bHHVFIiKDFAq5VlYD7/hjytbfz0dm7eeOZ1+nuzcVdVUiIoBCIRpn/gkUVXBj7G66+9Lc+fyWqCsSEQEUCtEoq4Eln2T8pv/mqmldfOeJ1+jpS0ddlYiIQiEyS/4XFFfxhfL76djbx9Jf60gkEYmeQiEqZTXwjk9S3fwAHz9xH0t//RptGihPRCKmUIjSmcHewp/F7iSdzfK1R9ZHXZGIFDiFQpRKq+Gcz1LW/DBfOel17nz+ddbv6I66KhEpYAqFqJ15I0ycy9Xt36CuKM3ND74cdUUiUsAUClGLJ+G9XyPevZWl0x/m0ZfbeHpjZ9RViUiBUijkg+lL4PQPMq/lx5xbtYMv3ruK3lQm6qpEpAApFPLFhX+HlY7n36tuY1N7N1996JWoKxKRAqRQyBdlNXDRP1DV8QJfn7mCW57axHObdkZdlYgUmJyHgplNM7PHzGytma0xs0+H82vM7GEzWx/eV+e6tsjNuxZOuID3bf8m7xzXyuf+a6XOdBaRnIpiTyENfNbd5wJLgBvNbC5wE/Cou88CHg0fFxYz+IOlWFkt30p+nd272vk/D66LuioRKSA5DwV33+7uK8LpbmAdMBW4HLg1XO1W4Ipc15YXyuvgqh9Q0rOVuyb9kB89s5nHXmmLuioRKRCR9imYWSOwAHgWmOTu28NFrcCkg2zzCTNrMrOm9vb2nNSZc9PfAe/638ze/Wu+OP4RPnXHC2xo00ltIjLyIgsFM6sA7gY+4+57hi5zdwf8QNu5+1J3X+juCydMmJCDSiOy5H/CnMv4WN9tnBVbw0dvbWJXT3/UVYnIGBdJKJhZkiAQbnf3n4azd5hZfbi8HijsNhMzuPybWN0svhn/f9R2reGTP1pOfzobdWUiMoZFcfSRAd8H1rn7vwxZdB9wQzh9A/CzXNeWd0qq4Pp7iJfXcEfZV+loXsWX7l1NsCMlIjL8othTOAu4HjjfzF4Mb5cANwPvMrP1wIXhY6maAtffS3GyiHsrv8qTTSv4vw+9omAQkRGRyPULuvuTgB1k8QW5rGXUqD0Brr+Hih9cws+qvsqlj99EfzrLX186h2DHS0RkeOiM5tFi8inYdcuopYtfVn6Fp556gi/ft4ZsVnsMIjJ8FAqjybTF2EcepKokwc9Kv8KmZ+/nC/esIp1R57OIDA+Fwmgz+VTsY49QNGEGtxZ9leyK2/jQfz6vw1VFZFgoFEajcVOxD/+C2Ann8X+T3+Xy1/+Rq//tYdZs64q6MhEZ5RQKo1VJFfzRnXDO57gy9gTf6/0cf/PtH3HvC1ujrkxERjGFwmgWT8IFX8I+9HMaKuDO+N/w8rKv8Kc/eo6OvX1RVycio5BCYSxoPJv4/3qK2Oz3cFPyJ/zJ+o/w+X/5Fvev3KbzGUTkiCgUxoqyGmLX/BCu/THHV8F3s3+LL/sIf3HLL3itfW/U1YnIKGGj+T/JhQsXelNTU9Rl5J/UfrK//heyT/0r6YxzR/ZCOuZ9ko9cfCa1FcVRVyciETOz5e6+8IDLFApj2K5m9j9yM0Vr7iLlMe7iIvoX/wlXvnMh48uKoq5ORCKiUCh0nRvZ8/DNlL+8jKwbD7GEttk3cPHF72NKdVnU1YlIjikUJLDzNXY+9k1K19xBabaHVdkZrJ78Pzj+9z/AojnHE4tpHCWRQqBQkDfr28uuZ35I6umlTOx9jT5P8ExiIftmX8m8d17JlLrqqCsUkRGkUJADc6dvywtsefw/qWu+j/HZ3fR4MatKFtI/82LmnHslEyZNibpKERlmCgV5e5k0rS8+RHvT3dS3Pkad7yTjxsbkLHbVn03dae9mxvx3Ekvq6CWR0U6hIEfGnS1rnmL7c/dSte1JZqZeIWFZeiliS+ls+iYvpHb22Uw++RysYmLU1YrIEVIoyDHZ2dnOq88+QN/6J6jbvZITs5tIWgaAjsRkumpOpei4xUycfSbFU06BUvVJiOQzhYIMG3enubWD9SufYt/GZ6jauZIT06/SYB2D63Ql6tg77kRik+YybvqplE09GSacCCXjIqxcRAYoFGREtXf3sebVV+lYv5xM62oqul6hMbOZmbaNYksNrrc3Uc3+iulYzQzKJ8+idNIsqDk+uJXVgC4tKpITCgXJKXdnx54+1m3bRWvzy/RsXUu88xXKe7bQ4K1Mj7UxhU5i9sZ3rzdeQW/ZFLJVDSRqplM24TgSVfVQMREqJkFlvYJDZJgcKhQSuS5Gxj4zY/K4EiaPq4c59cA7Achmna2797O+fS+/bN1J9/aNpDs2UNTVzLjeFur7O2jo2sCUlmdI2L7fed50rJje0klkKqcSr5pMcWUdycoJQViU1UL5BCivC+5LqyEWz/FPLjL6KRQkZ2IxY1pNGdNqynjnSROB2YPLUpksrV29tOzaz+pd+9jR3kHPzm30d7WS2dNK0b4d1KY7mJLqpL67k7ptr1Fj3SQPEB4AjpFKVpEpqcZLa4iVV5MsqyZeVg2l46E0DJKyWiirDkKktBqKx0FMgwdL4VIoSF5IxmODgQG1wDRgweByd6e7L03bnl5au/pY0d1LW3cfHV099OxuI93dAfvaie/rpKR/J9XWzfh0NzW93YzfvZdx9hrj6GGc7aPS9hEne8A6HCOVqCCbLMOT5cM9JYAAAAskSURBVFBUhhWVEysqJV5URryoDIoroLgquPpd8TgoKoNECSSKIVEaPE6WQVHFkOny4KJIInlOoSCjgplRVZKkqiTJzImVh1w3ncmye3+KXT39dPb0s7Onny37Uuza10/X/hS79/bS37ML39eJ7dtFvK+TZP8eyjLdjLO9VKX3UdbbR5n1UkYfpXRTYp2U0k+J9VNhvVSxj2L6j+hnyMaSZOMleKIYT5RCohhLlmJFZVhRBbHicixRDBaHWCLYY0mUQLI0CJaB6UQxxIvD+yTEkhBPQLwoWC9ZOmTdIffqj5HDoFCQMScRj1FXUUxdRTGzjmC7VCbL3t40e3pTdA+5396bZm/fG7eevjQ9fRl6e/fjvV1k+/eR7ttPJtWLp/YTS+0jnt5HGb2UWV8YLH2UWXBfTIpi66eYFKX0U0Y3pdZOGX0UW5qEZYnjJMmQJEUx/UccQAeSiRXhsWRwiyfBEkG/y8DNYpjFMDOwOJYsgWRZGFqlmA00qxlYLAiheDIMp6IhAVUUBJpnwQE8XD/55vViiXA6MSSwLJiOJcP1w+WEy8PaBoMyWRKs69k3bgMGnjNeHKyXKA3CUw5J75BIKBmPUV1eRHX5sV9rIpt19qcy7OvP0JvKsD+VYX9/+DidoS+VoTeVpS0VLO9NZdmfCub3pbPhvAz9mSx9qSypdArv78UzfXiqF0v3QrqPbCYFmRSeSRHL9pP0PkpIUUofpRaESQkpSsIQSpAmGd4SZIlbljgZ4mQxHMOJ4cTJUkyKEuugjF5KSGHmg5dqTFiWBBmKSJEkTRFp4uF9PstaAo/FgVh4HwacGQPBY57GssENwONJPB4En8eLwmALps0MPHjvcMcGQzaBxYLQtVg8CDKLQTYFmTRk+oMAGxqM8WS4lxh/S1AexOkfhBPOH/b3KK9CwcwuBr4OxIHvufvNEZckclRiMaO8OEF5cW5/xTJZpz+dpT+dpS+TIZVxUuksqUyWvnSWdNZJZbLBvKyTzgTL+jPB/HTG6c9kSWcG1nUy2SypjJPOBssHp8Pt0xknlXWyWSedyUA2QzabJpUleP0MuGewbArSKSzbD9k0Mc8E05k0WXfcnXTWwbPEwj/KcYJ7h+APL5AkQ0m491Rq/STIkMXIEsMJ+oUG1jWgiBQl9Ac36yeOEyNLjOxg31KM7MC+SBhvwc3wwRAtIk2RpcMgDAIRCCM0CBUjCMs4/SQtM/ga8bC6NHFSliBDAseI00vSMmFYZ8L1gucYmgnGmx4A0FF2FmeM5VAwszjwTeBdQAvwvJnd5+5ro61MZPSIx4zSojilRXFg7HRsZ7NOxp1MNrx5EEJZh3Q2SzbL4LzMW9fNOu4MzssOrOf+pu3S4boQPG/W39h2YDrjsNffeI6s88Zz+hvb+ZvmBwdKZLKO8+blPrh+UE/wOPh5fUgd2cFtg+dyh2tmTRuR9zpvQgFYDGxw99cAzOwnwOWAQkGkwMViRgwjqVNPRlw+HZA9Fdgy5HFLOO9NzOwTZtZkZk3t7e05K05EpBDkUygcFndf6u4L3X3hhAkToi5HRGRMyadQ2EpwxtKAhnCeiIjkSD6FwvPALDObYWZFwLXAfRHXJCJSUPKmo9nd02b2J8BDBIek3uLuayIuS0SkoORNKAC4+wPAA1HXISJSqPKp+UhERCKmUBARkUGj+sprZtYObD7KzeuAjrddKxr5Wlu+1gX5W1u+1gX5W1u+1gVjp7bj3P2Ax/SP6lA4FmbWdLDL0UUtX2vL17ogf2vL17ogf2vL17qgMGpT85GIiAxSKIiIyKBCDoWlURdwCPlaW77WBflbW77WBflbW77WBQVQW8H2KYiIyO8q5D0FERF5C4WCiIgMKshQMLOLzewVM9tgZjdFXMstZtZmZquHzKsxs4fNbH14Xx1BXdPM7DEzW2tma8zs0/lQm5mVmNlzZrYyrOvvwvkzzOzZ8DO9MxxUMRJmFjezF8zs5/lSm5k1m9kqM3vRzJrCeZF/z8I6xpvZMjN72czWmdmZUddmZieF79XAbY+ZfSbquobU92fh93+1md0R/l4My/es4EJhyGU/3wPMBf7QzOZGWNIPgIvfMu8m4FF3nwU8Gj7OtTTwWXefCywBbgzfp6hr6wPOd/d5wHzgYjNbAvwT8DV3nwnsAj6a47qG+jSwbsjjfKntne4+f8ix7FF/lgO+DvzC3WcD8wjeu0hrc/dXwvdqPnAGsA+4J+q6AMxsKvApYKG7n0IwgOi1DNf3zMPrgxbKDTgTeGjI488Dn4+4pkZg9ZDHrwD14XQ98EoevG8/I7h+dt7UBpQBK4B3EJzJmTjQZ5zjmhoI/licD/yc4DLrkdcGNAN1b5kX+WcJjAM2ER70kk+1DanlIuCpfKmLN65SWUMwqOnPgXcP1/es4PYUOMzLfkZskrtvD6dbgUlRFmNmjcAC4FnyoLaweeZFoA14GNgI7Hb3dLhKlJ/pvwJ/CWTDx7XkR20O/NLMlpvZJ8J5kX+WwAygHfjPsMnte2ZWnie1DbgWuCOcjrwud98K/DPwOrAd6AKWM0zfs0IMhVHFg9iP7LhhM6sA7gY+4+57hi6LqjZ3z3iwW98ALAZm57qGAzGz9wJt7r486loO4Gx3P52g2fRGMzt36MIIv2cJ4HTg2+6+AOjhLU0yUf4OhO3ylwH/9dZlUdUV9mNcThCoU4ByfrcJ+qgVYiiMhst+7jCzeoDwvi2KIswsSRAIt7v7T/OpNgB33w08RrCrPN7MBq4PEtVnehZwmZk1Az8haEL6ej7UFv53ibu3EbSNLyY/PssWoMXdnw0fLyMIiXyoDYIQXeHuO8LH+VDXhcAmd2939xTwU4Lv3rB8zwoxFEbDZT/vA24Ip28gaM/PKTMz4PvAOnf/l3ypzcwmmNn4cLqUoJ9jHUE4XBlVXQDu/nl3b3D3RoLv1a/c/bqoazOzcjOrHJgmaCNfTR58z9y9FdhiZieFsy4A1uZDbaE/5I2mI8iPul4HlphZWfh7OvCeDc/3LKrOmyhvwCXAqwRt0V+MuJY7CNoFUwT/NX2UoB36UWA98AhQE0FdZxPsGr8EvBjeLom6NuA04IWwrtXA34TzjweeAzYQ7OoXR/y5ngf8PB9qC19/ZXhbM/Cdj/qzHFLffKAp/EzvBarzoTaCZplOYNyQeZHXFdbxd8DL4e/AD4Hi4fqeaZgLEREZVIjNRyIichAKBRERGaRQEBGRQQoFEREZpFAQEZFBCgWRiJjZeQMjqYrkC4WCiIgMUiiIvA0z+0B4DYcXzew/wgH59prZ18Ix7R81swnhuvPN7Bkze8nM7hkYb9/MZprZI+F1IFaY2Qnh01cMuZbA7eEZqiKRUSiIHIKZzQGuAc7yYBC+DHAdwdmuTe5+MvAE8OVwk9uAv3L304BVQ+bfDnzTg+tA/B7BWewQjD77GYJrexxPMIaNSGQSb7+KSEG7gOAiK8+H/8SXEgyClgXuDNf5EfBTMxsHjHf3J8L5twL/FY47NNXd7wFw916A8Pmec/eW8PGLBNfWeHLkfyyRA1MoiByaAbe6++ffNNPsS29Z72jHi+kbMp1Bv5MSMTUfiRzao8CVZjYRBq9rfBzB787AiJR/BDzp7l3ALjM7J5x/PfCEu3cDLWZ2RfgcxWZWltOfQuQw6b8SkUNw97Vm9tcEVy2LEYxmeyPBxWAWh8vaCPodIBiy+DvhH/3XgA+H868H/sPMvhI+x1U5/DFEDptGSRU5Cma2190roq5DZLip+UhERAZpT0FERAZpT0FERAYpFEREZJBCQUREBikURERkkEJBREQG/X/y23mm2UMSOQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(h.history['loss'])\n",
        "plt.plot(h.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5eodErTxg9BJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "8524ffa7-fd14-41e3-c703-c6dd4b03831c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(h.history['accuracy'])\n",
        "plt.plot(h.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "pxSSK5SPhnKL"
      },
      "outputs": [],
      "source": [
        "#Evaluation and confusion matrix creation:\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "x_test = np.asarray(list(map(lambda x: x[0], tfds.as_numpy(resized_ds_test_unbatched))))\n",
        "y_test_orig = np.asarray(list(map(lambda x: x[1], tfds.as_numpy(resized_ds_test_unbatched))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Tg4EdPBuc7fW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f14c41-f9ac-41d5-974b-f3a592d05ac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "sYYhORws1NnZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15f501b8-c108-4b09-9964-7a6496303468"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "if loss!='sparse_categorical_crossentropy':\n",
        "    false_arr = np.full(shape=len(class_list), fill_value = False)\n",
        "    #y_pred = np.empty(shape=y_test_orig.shape[-1])\n",
        "    i=0\n",
        "    for i, pred in enumerate(predictions):\n",
        "        temp_arr = copy.deepcopy(false_arr)\n",
        "        np.put(temp_arr, np.argmax(pred), True)\n",
        "        if i==0:\n",
        "            y_pred = copy.deepcopy(temp_arr)\n",
        "        else:\n",
        "            y_pred = np.vstack([y_pred, temp_arr])\n",
        "    display(y_pred.shape)\n",
        "else:\n",
        "    y_pred = np.argmax(predictions, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "o-iQ19WTaE9s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d53a9bae-7794-46ab-fce1-e4d2c45104dd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(y_test_orig.shape)\n",
        "display(y_pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "phcwIL8RJQNQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "1135b26c-6b77-4eaa-af2d-fe681dfa3376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[832,  27,  37,  20,  21,   2,  11,  17,  21,  12],\n",
              "       [ 16, 844,  12,   7,   2,   2,  31,   4,   7,  75],\n",
              "       [ 71,  13, 585,  66,  93,   7, 110,  24,  18,  13],\n",
              "       [ 28,  19,  71, 480,  74,  41, 172,  40,  27,  48],\n",
              "       [ 16,   2,  58,  13, 765,   5, 114,  15,   6,   6],\n",
              "       [ 10,  13,  49, 267,  67, 349, 126,  44,  29,  46],\n",
              "       [  3,   6,  12,  15,  30,   3, 911,   5,   7,   8],\n",
              "       [ 24,  10,  37,  78, 263,  10,  64, 465,  18,  31],\n",
              "       [323,  46,  55,  28,  15,  10,  38,  12, 425,  48],\n",
              "       [ 41,  95,   9,  36,   8,   1,  51,  15,  13, 731]])"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.61      0.83      0.70      1000\n",
            "  automobile       0.79      0.84      0.81      1000\n",
            "        bird       0.63      0.58      0.61      1000\n",
            "         cat       0.48      0.48      0.48      1000\n",
            "        deer       0.57      0.77      0.65      1000\n",
            "         dog       0.81      0.35      0.49      1000\n",
            "        frog       0.56      0.91      0.69      1000\n",
            "       horse       0.73      0.47      0.57      1000\n",
            "        ship       0.74      0.42      0.54      1000\n",
            "       truck       0.72      0.73      0.72      1000\n",
            "\n",
            "   micro avg       0.64      0.64      0.64     10000\n",
            "   macro avg       0.66      0.64      0.63     10000\n",
            "weighted avg       0.66      0.64      0.63     10000\n",
            " samples avg       0.64      0.64      0.64     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Confusion Matrix')\n",
        "if loss != 'sparse_categorical_crossentropy':\n",
        "    matrix = confusion_matrix(y_test_orig.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "else:\n",
        "    matrix = confusion_matrix(y_test_orig, y_pred)\n",
        "display(matrix)\n",
        "\n",
        "# Print Classification Report\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test_orig, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5FRx9tVhibX"
      },
      "source": [
        "NOT using below things"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7NaFdDuTQoyT"
      },
      "outputs": [],
      "source": [
        "def ret_as_numpy():\n",
        "    test = tfds.load(DataSet, split='test', as_supervised=True)\n",
        "    test = prepare(test)\n",
        "    test = tfds.as_numpy(test)\n",
        "    return test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Si_MguzMQuZL"
      },
      "outputs": [],
      "source": [
        "test_as_np = ret_as_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "xWYWlODgQrFy"
      },
      "outputs": [],
      "source": [
        "def evaluate_float_model(model, test):\n",
        "    test_labels = []\n",
        "    \n",
        "    # Run predictions on every image in the \"test\" dataset.\n",
        "    prediction_digits = []\n",
        "    for i, test_example in enumerate(test):\n",
        "        if i % 1000 == 0:\n",
        "            print('Evaluated on {n} results so far.'.format(n=i))\n",
        "        test_labels.append(np.argmax(test_example[-1]))\n",
        "        test_image = test_example[0]\n",
        "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "        # the model's input data format.\n",
        "        #display(test_image.shape)\n",
        "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "        #test_image = np.expand_dims(test_image, axis=3).astype(np.float32)\n",
        "        #display(test_image.shape)\n",
        "        \n",
        "        # Run inference.\n",
        "        output = model(test_image, training=False)\n",
        "        # Post-processing: remove batch dimension and find the digit with highest\n",
        "        # probability.\n",
        "        output = output.numpy()\n",
        "        #display(output[0])\n",
        "        digit = np.argmax(output[0])\n",
        "        prediction_digits.append(digit)\n",
        "        \n",
        "    print('\\n')\n",
        "    #display(output[0])\n",
        "    #display(output)\n",
        "    #display(digit)\n",
        "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "    #display(prediction_digits)\n",
        "    #display(test_labels)\n",
        "    prediction_digits = np.array(prediction_digits)\n",
        "    accuracy = (prediction_digits == test_labels).mean()\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "BOHIU_J3QxE7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39a7f943-3944-4728-e25c-3642569b23da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated on 0 results so far.\n",
            "Evaluated on 1000 results so far.\n",
            "Evaluated on 2000 results so far.\n",
            "Evaluated on 3000 results so far.\n",
            "Evaluated on 4000 results so far.\n",
            "Evaluated on 5000 results so far.\n",
            "Evaluated on 6000 results so far.\n",
            "Evaluated on 7000 results so far.\n",
            "Evaluated on 8000 results so far.\n",
            "Evaluated on 9000 results so far.\n",
            "\n",
            "\n",
            "Float test_accuracy: 0.6387\n"
          ]
        }
      ],
      "source": [
        "test_accuracy_Float = evaluate_float_model(model, test_as_np)\n",
        "\n",
        "print('Float test_accuracy:', test_accuracy_Float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_Q2Is9IY-Oo"
      },
      "source": [
        "Float checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q tensorflow-model-optimization\n",
        "import tensorflow_model_optimization as tfmot\n",
        "quantize_model = tfmot.quantization.keras.quantize_model"
      ],
      "metadata": {
        "id": "5i9kUxj-4wNG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_aware_model = quantize_model(model)\n",
        "q_aware_model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "q_aware_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "yWycqRCE4yBu",
        "outputId": "e3a0d5e2-bbb9-45c0-cb2d-32b5845bc76e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-8a502a91d2dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mq_aware_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mq_aware_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mq_aware_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\u001b[0m in \u001b[0;36mquantize_model\u001b[0;34m(to_quantize)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0mannotated_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantize_annotate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_quantize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mquantize_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotated_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_model_optimization/python/core/keras/metrics.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMonitorBoolGauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FAILURE_LABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_gauge\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_model_optimization/python/core/keras/metrics.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMonitorBoolGauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUCCESS_LABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\u001b[0m in \u001b[0;36mquantize_apply\u001b[0;34m(model, scheme)\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;31m# `QuantizeConfig`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m   return keras.models.clone_model(\n\u001b[0m\u001b[1;32m    480\u001b[0m       transformed_model, input_tensors=None, clone_function=_quantize)\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/models/cloning.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             return _clone_sequential_model(\n\u001b[0m\u001b[1;32m    503\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclone_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/models/cloning.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0m_clone_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m             \u001b[0;32melse\u001b[0m \u001b[0mlayer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         )\n\u001b[1;32m    365\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloned_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\u001b[0m in \u001b[0;36m_quantize\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    427\u001b[0m           \u001b[0;34m'instance to the `quantize_annotate_layer` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m           'API.')\n\u001b[0;32m--> 429\u001b[0;31m       raise RuntimeError(\n\u001b[0m\u001b[1;32m    430\u001b[0m           error_msg.format(layer.name, layer.__class__,\n\u001b[1;32m    431\u001b[0m                            quantize_registry.__class__))\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Layer batch_normalization:<class 'keras.layers.normalization.batch_normalization.BatchNormalization'> is not supported. You can quantize this layer by passing a `tfmot.quantization.keras.QuantizeConfig` instance to the `quantize_annotate_layer` API."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantize_train, quant_train_info = tfds.load(DataSet, split='train + test[:75%]', with_info=True, as_supervised=True)\n",
        "filtered_quantize_train = quantize_train.filter(lambda x, y: filter_fn(y, class_list))\n",
        "\n",
        "resized_quantize_train = prepare(filtered_quantize_train)"
      ],
      "metadata": {
        "id": "sNkctNDh410F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resized_quantize_train = resized_quantize_train.batch(BATCH_SIZE)\n",
        "h = q_aware_model.fit(resized_quantize_train, epochs=5, validation_data = resized_ds_test)"
      ],
      "metadata": {
        "id": "blO0aYaP44O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(h.history['loss'])\n",
        "plt.plot(h.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WButHzSy5BTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_tflite_model = converter.convert()"
      ],
      "metadata": {
        "id": "GbugbXtI5Ecm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(interpreter, test):\n",
        "    test_labels = []\n",
        "\n",
        "\n",
        "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "    \n",
        "    # Run predictions on every image in the \"test\" dataset.\n",
        "    prediction_digits = []\n",
        "    for i, test_example in enumerate(test):\n",
        "        if i % 1000 == 0:\n",
        "            print('Evaluated on {n} results so far.'.format(n=i))\n",
        "        test_labels.append(np.argmax(test_example[-1]))\n",
        "        test_image = test_example[0]\n",
        "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "        # the model's input data format.\n",
        "        #display(test_image.shape)\n",
        "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "        #test_image = np.expand_dims(test_image, axis=3).astype(np.float32)\n",
        "        #display(test_image.shape)\n",
        "        interpreter.set_tensor(input_index, test_image)\n",
        "        \n",
        "        # Run inference.\n",
        "        interpreter.invoke()\n",
        "        \n",
        "        # Post-processing: remove batch dimension and find the digit with highest\n",
        "        # probability.\n",
        "        output = interpreter.tensor(output_index)\n",
        "        digit = np.argmax(output()[0])\n",
        "        prediction_digits.append(digit)\n",
        "        \n",
        "    print('\\n')\n",
        "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "    prediction_digits = np.array(prediction_digits)\n",
        "    accuracy = (prediction_digits == test_labels).mean()\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "iXBCHsjF5JiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Models obtained from TfLiteConverter can be run in Python with Interpreter.\n",
        "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
        "#Since TensorFlow Lite pre-plans tensor allocations to optimize inference, the user needs to call allocate_tensors() before any inference.\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "test_accuracy = evaluate_model(interpreter, test_as_np)\n",
        "\n",
        "print('Quant TFLite test_accuracy:', test_accuracy)\n",
        "#print('Quant TF test accuracy:', q_aware_model_accuracy)"
      ],
      "metadata": {
        "id": "rWyXRobN5NU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DIR = \"CadenceNet_Float\"\n",
        "model.save(MODEL_DIR, save_format=\"tf\")"
      ],
      "metadata": {
        "id": "KxEHJlru5PlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tf2onnx==1.8.4\n",
        "!python -m tf2onnx.convert --saved-model /content/CadenceNet_Float/ --output /content/CadenceNetOriginal_Float.onnx"
      ],
      "metadata": {
        "id": "VHzmQxaT5R3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quant_file = \"/content/CadenceNetOriginal_QAT.tflite\"\n",
        "open(quant_file, \"wb\").write(quantized_tflite_model)"
      ],
      "metadata": {
        "id": "-UgJyPkX5UKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5iITOiiRP0M"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"Float model in Mb: \", os.path.getsize(\"/content/CadenceNetOriginal_Float.onnx\") / float(2**20))\n",
        "print(\"Quantized model in Mb: \", os.path.getsize(quant_file) / float(2**20))\n",
        "print(\"Float Model Accuracy: \", test_accuracy_Float)\n",
        "print(\"Quantized Model Accuracy: \", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fOfhD35IW0f"
      },
      "outputs": [],
      "source": [
        "!pip install onnxruntime\n",
        "import onnxruntime as rt\n",
        "\n",
        "sess = rt.InferenceSession(\"/content/CadenceNetOriginal_Float.onnx\")\n",
        "input_name = sess.get_inputs()[0].name\n",
        "output_name = sess.get_outputs()[0].name\n",
        "x = np.random.random((1,IMG_SIZE,IMG_SIZE,NUM_CHANNELS))\n",
        "x = x.astype(np.float32)\n",
        "res = sess.run([output_name], {input_name: x})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_byw6-0Um7c"
      },
      "outputs": [],
      "source": [
        "indices = tf.convert_to_tensor([0, 1, 2])\n",
        "depth = 3\n",
        "indic = tf.convert_to_tensor([3, 5, 8])\n",
        "tf.math.multiply(indices, indic)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ftfq2j6b0CrC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}