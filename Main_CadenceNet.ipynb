{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeNovice/PSW/blob/main/Main_CadenceNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtuzdD-Y0hx9"
      },
      "source": [
        "TODO: Refer\n",
        "\n",
        "https://debuggercafe.com/getting-95-accuracy-on-the-caltech101-dataset-using-deep-learning/\n",
        "\n",
        "Data Pipeline:\n",
        "https://www.tensorflow.org/api_docs/python/tf/data/Dataset#as_numpy_iterator\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPUNbkOBLRGr"
      },
      "source": [
        "Loading the Caltech Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Q-XcSlHRLMMf"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "#For plotting the dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#Data pipeline preparation\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "#model building\n",
        "from tensorflow.keras import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DETpDXuOIHT"
      },
      "outputs": [],
      "source": [
        "(ds, ds_info) = tfds.load('caltech101', with_info=True)\n",
        "ds_train = ds[\"train\"]\n",
        "ds_test = ds[\"test\"]\n",
        "display(ds_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(type(ds_train))\n",
        "for example in ds_train:\n",
        "    image, label = example[\"image\"], example[\"label\"]\n",
        "    plt.imshow(image)\n",
        "    display(label)\n",
        "    break\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fS8HC9GrwA-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prTD3lYBb1jk"
      },
      "source": [
        "Data Preprocessing\n",
        "\n",
        "We could use adapt() methods to get normlazation (feature wise) parameters. https://www.tensorflow.org/guide/keras/preprocessing_layers#the_adapt_method\n",
        "\n",
        "https://stackoverflow.com/questions/57657386/tensorflow-datasets-reshape-images\n",
        "\n",
        "\n",
        "MAINLY:\n",
        "https://www.tensorflow.org/datasets/keras_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVWbmo7eS-N2"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 224\n",
        "NUM_CHANNELS = 3\n",
        "BATCH_SIZE=128\n",
        "\n",
        "def map_func(example):\n",
        "    resized_image = tf.image.resize_with_crop_or_pad(example[\"image\"], 224, 224)        #TODO: Remove crop as muh as possible\n",
        "    label = example[\"label\"]\n",
        "    return {\"image\":resized_image, \"label\":label}\n",
        "\n",
        "\n",
        "resized_ds_train = ds_train.map(map_func, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "input_shape = ()\n",
        "display(type(resized_ds_train))\n",
        "for example in resized_ds_train:\n",
        "    image, label = example[\"image\"], example[\"label\"]\n",
        "    plt.imshow(image)\n",
        "    display(label)\n",
        "    input_shape = image.shape\n",
        "    break\n",
        "plt.show()\n",
        "print(\"New resized shape for the dataset = \" + str(input_shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtQ38QKWw53M"
      },
      "source": [
        "display few examples"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = tfds.show_examples(ds_train, ds_info)"
      ],
      "metadata": {
        "id": "TcBi8KWv10Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeaeP_-bTf4A"
      },
      "outputs": [],
      "source": [
        "#ds_example = ds_train.take(10)\n",
        "fig = tfds.show_examples(resized_ds_train, ds_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuc6xq51_uK6"
      },
      "source": [
        "Resizing and re-scaling images to a given dataset.\n",
        "Tutorial used: https://www.tensorflow.org/tutorials/images/data_augmentation\n",
        "\n",
        "For data pipeline you may also refer to\n",
        "https://github.com/tensorflow/datasets/issues/720"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSpCep86OIfT"
      },
      "source": [
        "Prepare the model\n",
        "For Batchnorm, refer https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization\n",
        "\n",
        "Here they say that During training, the layer normalizes its output using the mean and standard deviation of the **current batch** of inputs.\n",
        "\n",
        "In order to make BatchNorm great, should we be using a larger batch as input?\n",
        "\n",
        "However, during Inference mode, the mean ans tsd deviation does not correspond to the current batch. Rather it is a moving mean and std dev of all the bacthes seen in training phase. (Thus, the parameters in inference phase for batch norm do not change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Mg41t1e5S8XA"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "#model.add(resize_and_rescale)\n",
        "\n",
        "kernel_size = (5,5)\n",
        "model.add(layers.Conv2D(64, kernel_size, input_shape = input_shape))       #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "model.add(layers.BatchNormalization())\n",
        "pool_size = (2,2)\n",
        "model.add(layers.MaxPool2D(pool_size))\n",
        "\n",
        "kernel_size = (3,3)\n",
        "model.add(layers.Conv2D(192, kernel_size))      #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "model.add(layers.BatchNormalization())\n",
        "pool_size = (2,2)\n",
        "model.add(layers.MaxPool2D(pool_size))\n",
        "\n",
        "kernel_size = (3,3)\n",
        "model.add(layers.Conv2D(64, kernel_size))       #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "model.add(layers.BatchNormalization())\n",
        "pool_size = (2,2)\n",
        "model.add(layers.MaxPool2D(pool_size))\n",
        "\n",
        "kernel_size = (3,3)\n",
        "model.add(layers.Conv2D(128, kernel_size))      #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "model.add(layers.BatchNormalization())\n",
        "pool_size = (2,2)\n",
        "model.add(layers.MaxPool2D(pool_size))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-PFEc55hxNm"
      },
      "outputs": [],
      "source": [
        "Learning_Rate = 1e-1                                            #https://machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=Learning_Rate)     #OR tf.keras.optimizers.SGD(learning_rate=Learning_Rate, momentum=0.0)\n",
        "model.compile( optimizer = opt, loss = 'categorical_crossentropy', metrics=['accuracy'] )\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh35uw-5keV2"
      },
      "source": [
        "Reference: https://github.com/tensorflow/datasets/issues/720"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUisIOtOiKHV"
      },
      "outputs": [],
      "source": [
        "resized_ds_train = resized_ds_train.cache()\n",
        "buffer_size = ds_info.splits['train'].num_examples\n",
        "resized_ds_train = resized_ds_train.shuffle(buffer_size)\n",
        "resized_ds_train = resized_ds_train.batch(BATCH_SIZE)\n",
        "resized_ds_train = resized_ds_train.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "h = model.fit( resized_ds_train, epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KPbjQBrRJMer"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpOGCy8i2+xmo6t7A6TeWs",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}