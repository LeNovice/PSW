{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAGh1iHnbqDaXuBwI55BiQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeNovice/PSW/blob/main/Original_CadenceNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IYvbodAaO5NT"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "#For plotting the dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#Data pipeline preparation\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "#model buildingZ\n",
        "from tensorflow.keras import models\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 10\n",
        "DataSet = 'caltech101'\n",
        "def num_samples_per_class(ds_train, get_top_10 = False, print_all = False):\n",
        "    vals = np.unique(np.fromiter(ds_train.map(lambda x, y: y), int), return_counts=True)\n",
        "    class_list = []\n",
        "    class_hist = []\n",
        "    for val,count in zip(*vals):\n",
        "        if print_all==True:\n",
        "            print(int(val), count)\n",
        "        class_hist.append((val,count))\n",
        "    if get_top_10 == True:\n",
        "        sorted_tuple = sorted(class_hist, key=lambda t: t[-1], reverse=True)[:(NUM_CLASSES + 1)]    #+1 because we are going to remove \"backround_google\" i.e. 4\n",
        "        class_list = [x for x,y in sorted_tuple]\n",
        "    return class_list\n",
        "\n",
        "def filter_fn(x, allowed_classes:list):\n",
        "    allowed_classes = tf.constant(allowed_classes)\n",
        "    isallowed = tf.equal(allowed_classes, tf.cast(x, allowed_classes.dtype))\n",
        "    reduced_sum = tf.reduce_sum(tf.cast(isallowed, tf.float32))\n",
        "    return tf.greater(reduced_sum, tf.constant(0.))"
      ],
      "metadata": {
        "id": "bJSJfW_tPA88"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = tfds.load(DataSet, split='train + test[:75%]', as_supervised=True)\n",
        "ds_test = tfds.load(DataSet, split='test', as_supervised=True)"
      ],
      "metadata": {
        "id": "2fLIbNS2PDZ1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_list = num_samples_per_class(ds_train, get_top_10=True)\n",
        "display(class_list)\n",
        "class_list = [i for i in class_list if i != 4]\n",
        "display(class_list)\n",
        "class_list.sort()\n",
        "resized_ds_train = ds_train.filter(lambda x, y: filter_fn(y, class_list)) # as_supervised\n",
        "resized_ds_test = ds_test.filter(lambda x, y: filter_fn(y, class_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "QOoGq7JtPGn8",
        "outputId": "81215cdb-a0c5-412e-8ca2-4c2d538d4dc0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[66, 1, 4, 38, 37, 95, 57, 9, 16, 54, 20]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[66, 1, 38, 37, 95, 57, 9, 16, 54, 20]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples_per_class(resized_ds_train, print_all=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DApyIbKhPISb",
        "outputId": "91b75d48-b38b-4586-82cf-3607d25986cd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 611\n",
            "9 104\n",
            "16 101\n",
            "20 87\n",
            "37 335\n",
            "38 337\n",
            "54 92\n",
            "57 155\n",
            "66 625\n",
            "95 192\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples_per_class(resized_ds_test, print_all=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8z2tJJ3PLsE",
        "outputId": "902a77fb-d753-4966-9013-242f24db3915"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 770\n",
            "9 98\n",
            "16 93\n",
            "20 77\n",
            "37 405\n",
            "38 405\n",
            "54 84\n",
            "57 170\n",
            "66 768\n",
            "95 209\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameters\n",
        "IMG_SIZE = 60\n",
        "NUM_CHANNELS = 3\n",
        "BATCH_SIZE=128\n",
        "\n",
        "input_shape = (IMG_SIZE,IMG_SIZE,NUM_CHANNELS)\n",
        "#Relabelling to avoid issues. Note that human readability is reduced by this\n",
        "table = tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=tf.constant(class_list, dtype=tf.int64),\n",
        "        values=tf.constant([0, 1, 2, 3, 4, 5, 6, 7, 8, 9],  dtype=tf.int64),\n",
        "    ),\n",
        "    default_value= tf.constant(0,  dtype=tf.int64)\n",
        ")\n",
        "\n",
        "#This function will be used in the graph execution hence @tf.function prefix\n",
        "@tf.function\n",
        "def map_func(label):\n",
        "    global class_list\n",
        "    mapped_label = table.lookup(label)\n",
        "    print(\"Label = \" + str(label) + \"\\t\" + \"Mapped Label = \" + str(mapped_label))\n",
        "    return mapped_label\n",
        "\n",
        "#Preprocessing done as part of the graph\n",
        "resize_and_rescale = tf.keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "  layers.Rescaling(1./255)\n",
        "])\n",
        "\n",
        "resize_layer = tf.keras.Sequential([\n",
        "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
        "])\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  layers.RandomRotation(0.2),\n",
        "])\n",
        "\n",
        "buffer_size = 30*NUM_CLASSES\n",
        "\n",
        "#Preprocessing function which invokes above graphs\n",
        "def prepare(ds, shuffle=False, augment=False, resize_only = False):\n",
        "    global buffer_size\n",
        "    global BATCH_SIZE\n",
        "    \n",
        "\n",
        "    # Resize and rescale all datasets.\n",
        "    if resize_only==True:\n",
        "        ds = ds.map(lambda x, y: (resize_layer(x), map_func(y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    else:\n",
        "        ds = ds.map(lambda x, y: (resize_and_rescale(x), map_func(y)), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    \n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size)\n",
        "        \n",
        "    # Batch all datasets.\n",
        "    #ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "    # Use data augmentation only on the training set.\n",
        "    if augment:\n",
        "        #f_ds = ds.filter(lambda x, y: filter_fn(y, [2,3,6]))    #[2,3,6] are the examples with lesser data. We are trying to bring back balance\n",
        "        #f_ds_aug = f_ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        #ds = ds.concatenate(f_ds_aug)\n",
        "        #ds_aug = ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        #ds = ds.concatenate(ds_aug)\n",
        "        ds_aug = ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        ds = ds.concatenate(ds_aug)\n",
        "\n",
        "        \n",
        "    # Use buffered prefetching on all datasets.\n",
        "    return ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "QdPKLGVdPNrk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resized_ds_train = prepare(resized_ds_train, augment=True)\n",
        "resized_ds_test = prepare(resized_ds_test, augment = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmLFCHD6PgLw",
        "outputId": "ef9b5ae8-7c32-4a3a-f8f7-9a58a571d35f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label = Tensor(\"label:0\", shape=(), dtype=int64)\tMapped Label = Tensor(\"None_Lookup/LookupTableFindV2:0\", shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples_per_class(resized_ds_train, print_all=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBn0xUIRPizz",
        "outputId": "761e1cba-b283-40d2-9bc5-8b3317a39781"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1222\n",
            "1 208\n",
            "2 202\n",
            "3 174\n",
            "4 670\n",
            "5 674\n",
            "6 184\n",
            "7 310\n",
            "8 1250\n",
            "9 384\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples_per_class(resized_ds_test, print_all=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktMrJP5GPkUD",
        "outputId": "d4477a01-90cc-4c20-d929-47ff2b6f3bf4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1540\n",
            "1 196\n",
            "2 186\n",
            "3 154\n",
            "4 810\n",
            "5 810\n",
            "6 168\n",
            "7 340\n",
            "8 1536\n",
            "9 418\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reg = tf.keras.regularizers.L2(0.01)\n",
        "reg = tf.keras.regularizers.L1L2(l1 =0.01, l2 = 0.1)\n",
        "#beta_regularizer = 0.1\n",
        "#gamma_regularizer = 0.1\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "\n",
        "kernel_size = (5,5)\n",
        "model.add(layers.Conv2D(64, kernel_size, input_shape = input_shape, padding=\"same\", kernel_regularizer = reg))       #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.ReLU())\n",
        "pool_size = (2,2)\n",
        "model.add(layers.MaxPool2D(pool_size))\n",
        "model.add(layers.Dropout(.2))\n",
        "\n",
        "kernel_size = (3,3)\n",
        "model.add(layers.Conv2D(192, kernel_size, padding=\"same\", kernel_regularizer = reg))      #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "model.add(layers.BatchNormalization())                                                      #beta_regularizer = beta_regularizer, gamma_regularizer = gamma_regularizer\n",
        "model.add(layers.ReLU())\n",
        "pool_size = (2,2)\n",
        "model.add(layers.MaxPool2D(pool_size))\n",
        "#model.add(layers.Dropout(.2))\n",
        "model.add(layers.SpatialDropout2D(0.2))\n",
        "\n",
        "kernel_size = (3,3)\n",
        "model.add(layers.Conv2D(64, kernel_size, padding=\"same\", kernel_regularizer = reg))       #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.ReLU())\n",
        "\n",
        "kernel_size = (3,3)\n",
        "model.add(layers.Conv2D(128, kernel_size, padding=\"same\", kernel_regularizer = reg))      #TODO: For instance, after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization.\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.ReLU())\n",
        "pool_size = (2,2)\n",
        "model.add(layers.MaxPool2D(pool_size))\n",
        "model.add(layers.SpatialDropout2D(0.2))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(.2))\n",
        "model.add(layers.Dense(NUM_CLASSES, activation='softmax', kernel_regularizer = reg))"
      ],
      "metadata": {
        "id": "ftnZ5OyvQB98"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Learning_Rate = 1e-5                                           \n",
        "opt = tf.keras.optimizers.Adam(learning_rate=Learning_Rate)     #OR tf.keras.optimizers.SGD(learning_rate=Learning_Rate, momentum=0.0)\n",
        "#model.compile( optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'] )\n",
        "model.compile( optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'] )\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpzOv6ADQP8L",
        "outputId": "30e3b805-4822-42dd-cd8c-975a40e3ba75"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (None, 60, 60, 64)        4864      \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 60, 60, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_10 (ReLU)             (None, 60, 60, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 30, 30, 64)        0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 30, 30, 192)       110784    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 30, 30, 192)      768       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_11 (ReLU)             (None, 30, 30, 192)       0         \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 15, 15, 192)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " spatial_dropout2d_1 (Spatia  (None, 15, 15, 192)      0         \n",
            " lDropout2D)                                                     \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 15, 15, 64)        110656    \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 15, 15, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_12 (ReLU)             (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 15, 15, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 15, 15, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_13 (ReLU)             (None, 15, 15, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 7, 7, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " spatial_dropout2d_2 (Spatia  (None, 7, 7, 128)        0         \n",
            " lDropout2D)                                                     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                62730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 364,682\n",
            "Trainable params: 363,786\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#h = model.fit( resized_ds_train, epochs=10)\n",
        "resized_ds_train = resized_ds_train.batch(BATCH_SIZE)\n",
        "resized_ds_test = resized_ds_test.batch(BATCH_SIZE)\n",
        "\n",
        "h = model.fit( resized_ds_train, epochs=20, validation_data = resized_ds_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "yKoB4BcEQVkU",
        "outputId": "d9591e72-04ef-437f-dc47-ae8fed6bb7a3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-61a13957d375>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresized_ds_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresized_ds_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mresized_ds_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresized_ds_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_9\" is incompatible with the layer: expected shape=(None, 60, 60, 3), found shape=(None, None, 60, 60, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(h.history['loss'])\n",
        "plt.plot(h.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FuOyiBsTQkYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ret_as_numpy():\n",
        "    test = tfds.load(DataSet, split='test', as_supervised=True)\n",
        "    test = prepare(test)\n",
        "    test = tfds.as_numpy(test)\n",
        "    return test"
      ],
      "metadata": {
        "id": "7NaFdDuTQoyT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_as_np = ret_as_numpy()"
      ],
      "metadata": {
        "id": "Si_MguzMQuZL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_float_model(model, test):\n",
        "    test_labels = []\n",
        "    \n",
        "    # Run predictions on every image in the \"test\" dataset.\n",
        "    prediction_digits = []\n",
        "    for i, test_example in enumerate(test):\n",
        "        if i % 1000 == 0:\n",
        "            print('Evaluated on {n} results so far.'.format(n=i))\n",
        "        test_labels.append(test_example[-1])\n",
        "        test_image = test_example[0]\n",
        "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "        # the model's input data format.\n",
        "        #display(test_image.shape)\n",
        "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "        #test_image = np.expand_dims(test_image, axis=3).astype(np.float32)\n",
        "        #display(test_image.shape)\n",
        "        \n",
        "        # Run inference.\n",
        "        output = model(test_image, training=False)\n",
        "        # Post-processing: remove batch dimension and find the digit with highest\n",
        "        # probability.\n",
        "        output = output.numpy()\n",
        "        #display(output[0])\n",
        "        digit = np.argmax(output[0])\n",
        "        prediction_digits.append(digit)\n",
        "        \n",
        "    print('\\n')\n",
        "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "    #display(prediction_digits)\n",
        "    #display(test_labels)\n",
        "    prediction_digits = np.array(prediction_digits)\n",
        "    accuracy = (prediction_digits == test_labels).mean()\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "xWYWlODgQrFy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy_Float = evaluate_float_model(model, test_as_np)\n",
        "\n",
        "print('Float test_accuracy:', test_accuracy_Float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOHIU_J3QxE7",
        "outputId": "a3df0384-6aa3-43ac-f2ed-601a4ecad4d2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated on 0 results so far.\n",
            "Evaluated on 1000 results so far.\n",
            "Evaluated on 2000 results so far.\n",
            "Evaluated on 3000 results so far.\n",
            "Evaluated on 4000 results so far.\n",
            "Evaluated on 5000 results so far.\n",
            "Evaluated on 6000 results so far.\n",
            "\n",
            "\n",
            "Float test_accuracy: 0.5037804076265615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Float checkpoint"
      ],
      "metadata": {
        "id": "g_Q2Is9IY-Oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q tensorflow-model-optimization\n",
        "import tensorflow_model_optimization as tfmot\n",
        "quantize_model = tfmot.quantization.keras.quantize_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fr6QAx7Qztb",
        "outputId": "c7e52758-d331-400c-d193-795fcd194a4c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/238.9 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m174.1/238.9 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_aware_model = quantize_model(model)\n",
        "q_aware_model.compile(optimizer = opt, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "q_aware_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfG_qAU4Q3DL",
        "outputId": "7a917bf0-6470-4021-9bd9-124d52dde786"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer (QuantizeLay  (None, 60, 60, 3)        3         \n",
            " er)                                                             \n",
            "                                                                 \n",
            " quant_conv2d (QuantizeWrapp  (None, 60, 60, 64)       4993      \n",
            " erV2)                                                           \n",
            "                                                                 \n",
            " quant_batch_normalization (  (None, 60, 60, 64)       257       \n",
            " QuantizeWrapperV2)                                              \n",
            "                                                                 \n",
            " quant_re_lu (QuantizeWrappe  (None, 60, 60, 64)       3         \n",
            " rV2)                                                            \n",
            "                                                                 \n",
            " quant_max_pooling2d (Quanti  (None, 30, 30, 64)       1         \n",
            " zeWrapperV2)                                                    \n",
            "                                                                 \n",
            " quant_conv2d_1 (QuantizeWra  (None, 30, 30, 192)      111169    \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_1  (None, 30, 30, 192)      769       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_re_lu_1 (QuantizeWrap  (None, 30, 30, 192)      3         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_max_pooling2d_1 (Quan  (None, 15, 15, 192)      1         \n",
            " tizeWrapperV2)                                                  \n",
            "                                                                 \n",
            " quant_conv2d_2 (QuantizeWra  (None, 15, 15, 64)       110785    \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_2  (None, 15, 15, 64)       257       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_re_lu_2 (QuantizeWrap  (None, 15, 15, 64)       3         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_conv2d_3 (QuantizeWra  (None, 15, 15, 128)      74113     \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            " quant_batch_normalization_3  (None, 15, 15, 128)      513       \n",
            "  (QuantizeWrapperV2)                                            \n",
            "                                                                 \n",
            " quant_re_lu_3 (QuantizeWrap  (None, 15, 15, 128)      3         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_max_pooling2d_2 (Quan  (None, 7, 7, 128)        1         \n",
            " tizeWrapperV2)                                                  \n",
            "                                                                 \n",
            " quant_flatten (QuantizeWrap  (None, 6272)             1         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_dropout (QuantizeWrap  (None, 6272)             1         \n",
            " perV2)                                                          \n",
            "                                                                 \n",
            " quant_dense (QuantizeWrappe  (None, 10)               62735     \n",
            " rV2)                                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 365,611\n",
            "Trainable params: 363,786\n",
            "Non-trainable params: 1,825\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantize_train, quant_train_info = tfds.load(DataSet, split='train + test[:75%]', with_info=True, as_supervised=True)\n",
        "filtered_quantize_train = quantize_train.filter(lambda x, y: filter_fn(y, class_list))\n",
        "\n",
        "resized_quantize_train = prepare(filtered_quantize_train)"
      ],
      "metadata": {
        "id": "AYdW-VK8Q5mT"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resized_quantize_train = resized_quantize_train.batch(BATCH_SIZE)\n",
        "h = q_aware_model.fit(resized_quantize_train, epochs=5, validation_data = resized_ds_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VQBS_obQ8DF",
        "outputId": "dcb58445-2f3f-4233-bd32-729718614dae"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "23/23 [==============================] - 11s 410ms/step - loss: 103.5816 - accuracy: 0.7253 - val_loss: 102.2401 - val_accuracy: 0.5522\n",
            "Epoch 2/5\n",
            "23/23 [==============================] - 6s 274ms/step - loss: 100.2163 - accuracy: 0.7621 - val_loss: 99.2292 - val_accuracy: 0.6013\n",
            "Epoch 3/5\n",
            "23/23 [==============================] - 6s 249ms/step - loss: 97.5099 - accuracy: 0.7906 - val_loss: 96.7705 - val_accuracy: 0.6351\n",
            "Epoch 4/5\n",
            "23/23 [==============================] - 6s 245ms/step - loss: 95.2851 - accuracy: 0.8003 - val_loss: 94.6298 - val_accuracy: 0.6976\n",
            "Epoch 5/5\n",
            "23/23 [==============================] - 4s 163ms/step - loss: 93.3335 - accuracy: 0.8161 - val_loss: 92.7477 - val_accuracy: 0.7188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(h.history['loss'])\n",
        "plt.plot(h.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "pHskuvDaRBPb",
        "outputId": "8b49e910-c4aa-4b3c-bb99-db2249cdb648"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_tflite_model = converter.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFq4nw4PRDYT",
        "outputId": "b6dc2c23-ede9-46de-8277-59a284d700cf"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, re_lu_layer_call_fn, re_lu_layer_call_and_return_conditional_losses while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(interpreter, test):\n",
        "    test_labels = []\n",
        "\n",
        "\n",
        "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "    \n",
        "    # Run predictions on every image in the \"test\" dataset.\n",
        "    prediction_digits = []\n",
        "    for i, test_example in enumerate(test):\n",
        "        if i % 1000 == 0:\n",
        "            print('Evaluated on {n} results so far.'.format(n=i))\n",
        "        test_labels.append(test_example[-1])\n",
        "        test_image = test_example[0]\n",
        "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "        # the model's input data format.\n",
        "        #display(test_image.shape)\n",
        "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "        #test_image = np.expand_dims(test_image, axis=3).astype(np.float32)\n",
        "        #display(test_image.shape)\n",
        "        interpreter.set_tensor(input_index, test_image)\n",
        "        \n",
        "        # Run inference.\n",
        "        interpreter.invoke()\n",
        "        \n",
        "        # Post-processing: remove batch dimension and find the digit with highest\n",
        "        # probability.\n",
        "        output = interpreter.tensor(output_index)\n",
        "        digit = np.argmax(output()[0])\n",
        "        prediction_digits.append(digit)\n",
        "        \n",
        "    print('\\n')\n",
        "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "    prediction_digits = np.array(prediction_digits)\n",
        "    accuracy = (prediction_digits == test_labels).mean()\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "bJbUyvBrRGBD"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Models obtained from TfLiteConverter can be run in Python with Interpreter.\n",
        "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
        "#Since TensorFlow Lite pre-plans tensor allocations to optimize inference, the user needs to call allocate_tensors() before any inference.\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "test_accuracy = evaluate_model(interpreter, test_as_np)\n",
        "\n",
        "print('Quant TFLite test_accuracy:', test_accuracy)\n",
        "#print('Quant TF test accuracy:', q_aware_model_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ol3wMK2RIjN",
        "outputId": "81b9818a-ffcb-4ba9-f053-8aa934297400"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluated on 0 results so far.\n",
            "Evaluated on 1000 results so far.\n",
            "Evaluated on 2000 results so far.\n",
            "Evaluated on 3000 results so far.\n",
            "Evaluated on 4000 results so far.\n",
            "Evaluated on 5000 results so far.\n",
            "Evaluated on 6000 results so far.\n",
            "\n",
            "\n",
            "Quant TFLite test_accuracy: 0.5698553583168968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DIR = \"CadenceNet_Float\"\n",
        "model.save(MODEL_DIR, save_format=\"tf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVX3TFb5RKeD",
        "outputId": "12845ef5-554d-44fc-8910-35f37ff18556"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tf2onnx\n",
        "!python -m tf2onnx.convert --saved-model /content/CadenceNet_Float/ --output /content/CadenceNetOriginal_Float.onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKEqxRdmRMOL",
        "outputId": "050f2fcd-3f2b-48ba-d003-851e8b2ffe9f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.13.0-py3-none-any.whl (442 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.3/442.3 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (1.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.8/dist-packages (from tf2onnx) (1.21.6)\n",
            "Collecting onnx>=1.4.1\n",
            "  Downloading onnx-1.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.8/dist-packages (from onnx>=1.4.1->tf2onnx) (4.4.0)\n",
            "Collecting protobuf<4,>=3.20.2\n",
            "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->tf2onnx) (2022.12.7)\n",
            "Installing collected packages: protobuf, onnx, tf2onnx\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m/usr/bin/python3: Error while finding module specification for 'tf2onnx.convert' (ModuleNotFoundError: No module named 'tf2onnx')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quant_file = \"/content/CadenceNetOriginal_QAT.tflite\"\n",
        "open(quant_file, \"wb\").write(quantized_tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLDe9u9sRORk",
        "outputId": "01812551-c9d9-4815-f252-be65a7f871e9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "381680"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Float model in Mb: \", os.path.getsize(\"/content/CadenceNetOriginal_Float.onnx\") / float(2**20))\n",
        "print(\"Quantized model in Mb: \", os.path.getsize(quant_file) / float(2**20))\n",
        "print(\"Float Model Accuracy: \", test_accuracy_Float)\n",
        "print(\"Quantized Model Accuracy: \", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "T5iITOiiRP0M",
        "outputId": "5bf39ad3-f2fd-4459-e679-2b7e440e006a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-13531ae925b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Float model in Mb: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/CadenceNetOriginal_Float.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Quantized model in Mb: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquant_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Float Model Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy_Float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Quantized Model Accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/genericpath.py\u001b[0m in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;34m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/CadenceNetOriginal_Float.onnx'"
          ]
        }
      ]
    }
  ]
}